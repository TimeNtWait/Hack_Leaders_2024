{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Baseline   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Цель: предсказать для каждого пользователя взятие/ невзятие каждого из четырех продуктов **в течение месяца после отчетной даты**, исторические данные по ним находятся в targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Profit77\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_float_dtype, is_integer_dtype\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import gc\n",
    "import glob\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# найтройки\n",
    "# Убираем ограничение отображемых колонок\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# Устанавливаем тему по умолчанию\n",
    "sb_dark = sns.dark_palette('skyblue', 8, reverse=True) # teal\n",
    "sns.set(palette=sb_dark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Включаем tqdm для pandas, чтобы можно было запускать progress_apply() вместо простого apply()\n",
    "tqdm.pandas() \n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = ''\n",
    "PATH_DATASET = PATH + 'datasets/sber_source/'\n",
    "PATH_DATASET_OUTPUT = PATH + 'datasets/'\n",
    "PATH_DATASET_EMBEDDINGS = PATH + 'datasets/embeddings/'\n",
    "\n",
    "PATH_DATASET_TARGET_TRAIN = PATH_DATASET + 'train_target.parquet/'\n",
    "PATH_DATASET_TARGET_TEST = PATH_DATASET + 'test_target_b.parquet/'\n",
    "\n",
    "# таргеты\n",
    "train_target_files = glob.glob(PATH_DATASET_TARGET_TRAIN + '/*.parquet')\n",
    "test_target_files = glob.glob(PATH_DATASET_TARGET_TEST + '/*.parquet')\n",
    "\n",
    "len(train_target_files), len(test_target_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del item_object\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.72 s\n",
      "Wall time: 1.54 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10246704, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Загружаем факты продаж продуктов по трейн клиентам\n",
    "train_target_df = pq.read_table(PATH_DATASET_OUTPUT + 'compress_train_target_files_07_06_2024.parquet').to_pandas()\n",
    "train_target_df = train_target_df.rename(columns={'mon': 'report_next_end'})\n",
    "train_target_df = train_target_df.reset_index()\n",
    "train_target_df = train_target_df[['client_id', 'report_next_end', 'target_1', 'target_2', 'target_3', 'target_4']]\n",
    "train_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.09 s\n",
      "Wall time: 864 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1407671, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Загружаем факты продаж продуктов по ТЕСТ клиентам\n",
    "test_target_df = pq.read_table(PATH_DATASET_OUTPUT + 'compress_test_target_files_08_06_2024.parquet').to_pandas()\n",
    "test_target_df = test_target_df.drop_duplicates(subset=['mon', 'client_id'])\n",
    "test_target_df = test_target_df.rename(columns={'mon': 'report_next_end'})\n",
    "test_target_df = test_target_df[['client_id', 'report_next_end', 'target_1', 'target_2', 'target_3', 'target_4']]\n",
    "test_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1548159, 6), (140488, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# добавляем предсказательный столбец в тестовые данные, чтобы расчитать таргет-фичи для них. Это последний период + месяц\n",
    "def add_submit_month(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    # ищем максимальную дату для каждого client_id\n",
    "    max_dates = df.groupby('client_id')['report_next_end'].max().reset_index()\n",
    "    # добавляем один месяц к максимальной дате\n",
    "    max_dates['new_report_next_end'] = max_dates['report_next_end'] + pd.DateOffset(months=1)\n",
    "    submit_df = max_dates[['client_id', 'new_report_next_end']].rename(columns={'new_report_next_end': 'report_next_end'})\n",
    "    df = pd.concat([df, submit_df], ignore_index=True)\n",
    "    df = df.sort_values(['client_id', 'report_next_end'])\n",
    "    # возвращаем итоговый датафрейм с добавленой строкой следующего месяца и связку клиент+отчетный период для сабмита\n",
    "    return df.fillna(0), submit_df\n",
    "\n",
    "test_target_df, submit_df = add_submit_month(test_target_df)\n",
    "test_target_df.shape, submit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "report_next_end\n",
       "2023-01-31    48877\n",
       "2022-11-30    46086\n",
       "2022-12-30    45525\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df['report_next_end'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00011c01bb22d8f62d9655f32d123dcca5ae55179f8266bdb8676e25321e8477'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df['client_id'][:1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12.6 s\n",
      "Wall time: 12.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10246704, 24), (1548159, 24))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Рассчитываем факт приобретения клиентом когда-либо продукта 1 или 2/3/4\n",
    "def get_group_targets(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    # Факт приобретения клиентом когда-либо продукта 1 или 2/3/4\n",
    "    df['is_target'] = df[['target_1', 'target_2', 'target_3', 'target_4']].max(axis=1)\n",
    "    \n",
    "    # Расширеный факт приобретения клиентом когда-либо группы продуктов \n",
    "    df['is_target_1_2'] = df[['target_1', 'target_2']].max(axis=1)\n",
    "    df['is_target_1_3'] = df[['target_1', 'target_3']].max(axis=1)\n",
    "    df['is_target_1_4'] = df[['target_1', 'target_4']].max(axis=1)\n",
    "    df['is_target_2_3'] = df[['target_2', 'target_3']].max(axis=1)\n",
    "    df['is_target_2_4'] = df[['target_2', 'target_4']].max(axis=1)\n",
    "    df['is_target_3_4'] = df[['target_3', 'target_4']].max(axis=1)\n",
    "    \n",
    "    df['is_target_123'] = df[['target_1', 'target_2', 'target_3']].max(axis=1)\n",
    "    df['is_target_134'] = df[['target_1', 'target_3', 'target_4']].max(axis=1)\n",
    "    df['is_target_124'] = df[['target_1', 'target_2', 'target_4']].max(axis=1)\n",
    "    df['is_target_234'] = df[['target_2', 'target_3', 'target_4']].max(axis=1)\n",
    "    \n",
    "    # Второй расширеный факт приобретения клиентом когда-либо группы продуктов \n",
    "    df['is_target_1_and_2'] = np.where(df[['target_1', 'target_2']].sum(axis=1) == 2, 1,0)\n",
    "    df['is_target_1_and_3'] = np.where(df[['target_1', 'target_3']].sum(axis=1) == 2, 1,0)\n",
    "    df['is_target_1_and_4'] = np.where(df[['target_1', 'target_4']].sum(axis=1) == 2, 1,0)\n",
    "    df['is_target_2_and_3'] = np.where(df[['target_2', 'target_3']].sum(axis=1) == 2, 1,0)\n",
    "    df['is_target_2_and_4'] = np.where(df[['target_2', 'target_4']].sum(axis=1) == 2, 1,0)\n",
    "    df['is_target_3_and_4'] = np.where(df[['target_3', 'target_4']].sum(axis=1) == 2, 1,0)\n",
    "    \n",
    "    # кол-во купленных продуктов\n",
    "    df['is_target_cnt'] = df[['target_1', 'target_2', 'target_3', 'target_4']].sum(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "test_target_df = get_group_targets(test_target_df)\n",
    "train_target_df = get_group_targets(train_target_df)\n",
    "\n",
    "train_target_df.shape, test_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_columns = ['target_1', 'target_2', 'target_3', 'target_4',\n",
    "                  'is_target', 'is_target_1_2', 'is_target_1_3',\n",
    "                  'is_target_1_4', 'is_target_2_3', 'is_target_2_4', 'is_target_3_4',\n",
    "                  'is_target_1_and_2', 'is_target_1_and_3', 'is_target_1_and_4',\n",
    "                  'is_target_2_and_3', 'is_target_2_and_4', 'is_target_3_and_4',\n",
    "                  'is_target_123', 'is_target_134', 'is_target_124', 'is_target_234',\n",
    "                  'is_target_cnt']\n",
    "len(target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [02:57<00:00,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 59s\n",
      "Wall time: 2min 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10246704, 68), (1548159, 68))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Надо определить для каждого месяца, покупал ли клиент ранее продукт или нет\n",
    "def is_prebuy_product(df:pd.DataFrame, target_col:str) -> pd.DataFrame:\n",
    "    # Сортируем по клиенту и отчетному периоду\n",
    "    df = df.sort_values(['client_id', 'report_next_end'])\n",
    "\n",
    "    # Создаем новую колонку c фактом предудыщей покупи\n",
    "    df[f'prebuy_{target_col}'] = (df.groupby('client_id')[target_col]\n",
    "                                   .cummax()\n",
    "                                   .shift(1)\n",
    "                                   .fillna(0)\n",
    "                                   .astype(int))\n",
    "    # Кол-во приобретенных продуктов\n",
    "    df[f'cnt_prebuy_{target_col}'] = (df.groupby('client_id')[target_col]\n",
    "                                           .cumsum()\n",
    "                                           .shift(1)\n",
    "                                           .fillna(0)\n",
    "                                           .astype(int))    \n",
    "    return df\n",
    "\n",
    "for tar_col in tqdm(target_columns):\n",
    "    test_target_df = is_prebuy_product(df=test_target_df, target_col=tar_col)\n",
    "    train_target_df = is_prebuy_product(df=train_target_df, target_col=tar_col)\n",
    "    \n",
    "train_target_df.shape, test_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 578 ms\n",
      "Wall time: 554 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1548159, 68)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Уменьшение размера датафрейма, для таргетов, транзакцй и для фичей\n",
    "def series_to_int(col_df:pd.Series):\n",
    "    \"\"\"\n",
    "    Перевод в целочисленные типы\n",
    "    \"\"\"\n",
    "    min_val = col_df.min()\n",
    "    max_val = col_df.max()\n",
    "    if min_val >= -128 and max_val <= 127:\n",
    "        col_df = col_df.astype('int8')\n",
    "    elif min_val >= -32768 and max_val <= 32767:\n",
    "        col_df = col_df.astype('int16')\n",
    "    elif min_val >= -2147483648 and max_val <= 2147483647:\n",
    "        col_df = col_df.astype('int32')\n",
    "    else:\n",
    "        col_df = col_df.astype('int64')\n",
    "    return col_df\n",
    "\n",
    "def compression_df(df:pd.DataFrame(), datetime_cols:List[str]=[], category_cols:List[str]=[]):\n",
    "    \"\"\"\n",
    "    Уменьшение размера датафрейма, для таргетов, транзакцй и для фичей\n",
    "    \"\"\"\n",
    "    float64_cols = list(df.select_dtypes(include='float64'))  \n",
    "    df[float64_cols] = df[float64_cols].astype('float32')\n",
    "    for col in df.columns:\n",
    "        if col in category_cols:\n",
    "            df[col] = df[col].astype('category')\n",
    "        elif col in datetime_cols:\n",
    "            if df[col].dtypes == 'object':\n",
    "                df[col] = pd.to_datetime(df[col])\n",
    "        # Если колонка содержит числа \n",
    "        elif is_integer_dtype(df[col]):\n",
    "            if df[col].dtypes == 'int8':\n",
    "                continue\n",
    "            else:\n",
    "                df[col] = series_to_int(df[col])\n",
    "        elif is_float_dtype(df[col]):\n",
    "            # Возможно ли перевести в число\n",
    "            if np.array_equal(df[col].fillna(0), df[col].fillna(0).astype(int)):\n",
    "                df[col] = df[col].fillna(0)\n",
    "                df[col] = series_to_int(df[col])\n",
    "    return df\n",
    "test_target_df = compression_df(test_target_df, \n",
    "                            datetime_cols=['report_end' ,'report_next_end'],\n",
    "                           )\n",
    "test_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10246704, 66)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_df = train_target_df.rename(columns={'mon': 'report_next_end'})\n",
    "train_target_df = train_target_df.set_index(['client_id','report_next_end'])\n",
    "train_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1548159, 66)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target_df = test_target_df.rename(columns={'mon': 'report_next_end'})\n",
    "test_target_df = test_target_df.set_index(['client_id','report_next_end'])\n",
    "test_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140488, 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df = submit_df.rename(columns={'mon': 'report_next_end'})\n",
    "submit_df = submit_df.set_index(['client_id','report_next_end'])\n",
    "submit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140488, 66)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Формируем тестовый датафрейм на базе сабмит фрейма\n",
    "submit_test_df = submit_df.merge(test_target_df, left_index=True, right_index=True)\n",
    "submit_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10246704, 66)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10246704, 66)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем val_clients_df test_clients_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_random_undersampling(df:pd.DataFrame, target_col:str, desired_ratio:float):\n",
    "#     \"\"\"\n",
    "#     Кастомный RandomUnderSampling, с указанием доли распредления desired_ratio.\n",
    "    \n",
    "#     df: исходный DataFrame.\n",
    "#     target_col: название столбца с целевой переменной.\n",
    "#     desired_ratio: желаемое соотношение меньшего класса к большему классу (между 0 и 1).\n",
    "    \n",
    "#     return: под-выборка исходного DataFrame с заданным соотношением классов.\n",
    "#     \"\"\"\n",
    "#     # Получаем распределение классов в исходном DataFrame\n",
    "#     class_counts = Counter(df[target_col])\n",
    "    \n",
    "#     # Определяем меньший и больший классы\n",
    "#     minority_class = min(class_counts, key=class_counts.get)\n",
    "#     majority_class = max(class_counts, key=class_counts.get)\n",
    "    \n",
    "#     # Вычисляем желаемое количество примеров меньшего класса\n",
    "#     minority_count = class_counts[minority_class]\n",
    "#     majority_count = int(minority_count / desired_ratio)\n",
    "    \n",
    "#     # Создаем под-выборки для меньшего и большего классов\n",
    "#     minority_subset = df[df[target_col] == minority_class]\n",
    "#     majority_subset = resample(df[df[target_col] == majority_class],\n",
    "#                                replace=False,\n",
    "#                                n_samples=majority_count,\n",
    "#                                random_state=53)\n",
    "    \n",
    "#     # Объединяем под-выборки и сохраняем исходный индекс\n",
    "#     resampled_df = pd.concat([minority_subset, majority_subset], ignore_index=False)\n",
    "    \n",
    "#     return resampled_df\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# # Разделение на трейн и тест будет производиться независимо для каждого таргета\n",
    "# # Разделять будем по клиентам, т.е. важно чтобы в трейне и тесте клиенты не совпадали\n",
    "# # Поэтому сначала схлопываем клиентов с признаком хотя бы раз покупал продукт в любом месяце\n",
    "# # Далее делим клиентов стратификацией по факту приобретения продукта\n",
    "# # Далее возвращаем все отчетные месяцы для клиентов train/test/val выборок\n",
    "# def split_train_test_val(df:pd.DataFrame, target_column:str='target_1'):\n",
    "#     client_any_one_target_df = df[[target_column, 'client_id']].groupby('client_id')[target_column].agg(lambda x: any(x)).reset_index()\n",
    "#     X_train, X_test, _, y_test = train_test_split(client_any_one_target_df['client_id'], \n",
    "#                                                         client_any_one_target_df[target_column], \n",
    "#                                                         test_size=0.1, \n",
    "#                                                         stratify=client_any_one_target_df[target_column], \n",
    "#                                                         random_state=53)\n",
    "#     X_test, X_val, _, _ = train_test_split(X_test, \n",
    "#                                            y_test, \n",
    "#                                            test_size=0.5, \n",
    "#                                            stratify=y_test, \n",
    "#                                            random_state=53)\n",
    "\n",
    "#     X_train = df[df['client_id'].isin(X_train.values)]\n",
    "#     X_val = df[df['client_id'].isin(X_val.values)]\n",
    "#     X_test = df[df['client_id'].isin(X_test.values)]\n",
    "\n",
    "#     assert len(set(X_train['client_id'].values)&set(X_test['client_id'].values)) == 0, 'Ошибка в разделение клиентов X_train и X_test'\n",
    "#     assert len(set(X_test['client_id'].values)&set(X_val['client_id'].values)) == 0, 'Ошибка в разделение клиентов  X_val и X_test'\n",
    "#     assert len(set(X_train['client_id'].values)&set(X_val['client_id'].values)) == 0, 'Ошибка в разделение клиентов X_train и X_val'\n",
    "    \n",
    "#     return X_train, X_val, X_test\n",
    "\n",
    "# sampling_train_target_df = custom_random_undersampling(train_target_df, 'is_target', desired_ratio=0.5)\n",
    "# sampling_train_target_df.shape\n",
    "\n",
    "# train_label_df, val_label_df, test_label_df = split_train_test_val(\n",
    "#                             sampling_train_target_df.reset_index()\n",
    "#                             )\n",
    "# # train_label_df.shape, val_label_df.shape, test_label_df.shape\n",
    "\n",
    "# val_clients_df = val_label_df[['client_id', 'report_next_end']].set_index(['client_id', 'report_next_end'])\n",
    "# test_clients_df = test_label_df[['client_id', 'report_next_end']].set_index(['client_id', 'report_next_end'])\n",
    "# # val_clients_df.to_csv('val_clients_df.csv')\n",
    "# # test_clients_df.to_csv('test_clients_df.csv')\n",
    "# val_clients_df.shape, test_clients_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30427, 2), (30191, 2))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считываем ранее сохраненные тестовыие и выалидационные наборы для чистоты эскпериментов по поиску лучшего сэмплера\n",
    "val_clients_df = pd.read_csv('val_clients_df.csv')\n",
    "test_clients_df = pd.read_csv('test_clients_df.csv')\n",
    "# val_clients_df = val_clients_df.set_index(['client_id', 'report_next_end'])\n",
    "# test_clients_df = test_clients_df.set_index(['client_id', 'report_next_end'])\n",
    "val_clients_df['report_next_end'] = pd.to_datetime(val_clients_df['report_next_end'])\n",
    "test_clients_df['report_next_end'] = pd.to_datetime(test_clients_df['report_next_end'])\n",
    "val_clients_df.shape, test_clients_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9728184, 68)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выбираем только тех клиентов которых нет в зафиксированной валидационной и тестовой выборках\n",
    "# assert False, \"переписать на индекс, чтобы не тянуть все по клиентам вал тест а только то что тестим\"\n",
    "sub_train_target_df = train_target_df.copy()\n",
    "sub_train_target_df = sub_train_target_df.reset_index()\n",
    "sub_train_target_df = sub_train_target_df[~(\n",
    "    (sub_train_target_df['client_id'].isin(val_clients_df['client_id']))|\n",
    "    (sub_train_target_df['client_id'].isin(test_clients_df['client_id']))\n",
    ")]\n",
    "\n",
    "sub_train_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем клиентов с 1м таргетом\n",
    "class_1_all_target_df = sub_train_target_df[sub_train_target_df['is_target'] == 1]\n",
    "# class_1_all_target_df = class_1_all_target_df.set_index(['client_id', 'report_next_end'])\n",
    "# class_1_all_target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_1_all_target_df.shape\n",
    "# class_0_all_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364494, 0)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Добавляем рандомные записи по нулевому классу (двойной размер от тех у которых хотя бы есть один таргет)\n",
    "random_0_class_df = sub_train_target_df[sub_train_target_df['is_target'] == 0].sample(len(class_1_all_target_df)*2, random_state=53)\n",
    "random_0_class_df = random_0_class_df[['client_id', 'report_next_end']]\n",
    "random_0_class_df = random_0_class_df.set_index(['client_id', 'report_next_end'])\n",
    "# class_0_all_target_df = pd.concat([class_0_all_target_df, random_0_class_df])\n",
    "# class_0_all_target_df.shape \n",
    "random_0_class_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182247, 0)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_1_all_target_df = class_1_all_target_df[['client_id', 'report_next_end']]\n",
    "class_1_all_target_df = class_1_all_target_df.set_index(['client_id', 'report_next_end'])\n",
    "class_1_all_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30427, 0), (30191, 0))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val_clients_df.shape, test_clients_df\n",
    "val_clients_df = val_clients_df.set_index(['client_id', 'report_next_end'])\n",
    "test_clients_df = test_clients_df.set_index(['client_id', 'report_next_end'])\n",
    "val_clients_df.shape, test_clients_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1_all_target_df['type'] = 'any_1_class'\n",
    "random_0_class_df['type'] = 'random_0_class'\n",
    "val_clients_df['type'] = 'val'\n",
    "test_clients_df['type'] = 'test'\n",
    "submit_df['type'] = 'submit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(747847, 3)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Формируем итоговый датасет вместе с итоговым сэмплем и вместе с тест и вал пользователями \n",
    "result_sample_Client_Month_df = pd.concat([class_1_all_target_df, random_0_class_df, val_clients_df, test_clients_df, submit_df])\n",
    "result_sample_Client_Month_df = result_sample_Client_Month_df.reset_index()\n",
    "result_sample_Client_Month_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit_df.reset_index().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(747847, 3)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохраняем в файл итоговый выбор пар клиент-месяц, с которыми будет работа в дальнейшем (например фичи будут рассчитываться только для них)\n",
    "result_sample_Client_Month_df.to_parquet(PATH_DATASET_OUTPUT + 'result_sample_Client_Month_df_12_06_2024.parquet')\n",
    "result_sample_Client_Month_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Старый сэмплер выбор в 0-ой класс пар таргет=1 и его прошлый месяц где таргет = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364494, 0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Определяем клиентов с 1м таргетом\n",
    "class_1_all_target_df = sub_train_target_df[sub_train_target_df['is_target'] == 1]\n",
    "# class_1_target_1 = class_1_target_1.reset_index()\n",
    "\n",
    "# Выбираем пользователей, которые покупали продукт\n",
    "# И далее выбираем их прошлые месяцы, если они там уже не покупали продукты, то идеальный негативный класс\n",
    "# т.к. состояние клиентов похоже, но в одном случае не покупалось а через месяц купил, значит что-то изменилось\n",
    "premon_select = class_1_all_target_df[['client_id', 'report_next_end']]\n",
    "premon_select['report_next_end'] = premon_select['report_next_end'] - pd.DateOffset(months=1)\n",
    "prepre_mon_select = class_1_all_target_df[['client_id', 'report_next_end']]\n",
    "prepre_mon_select['report_next_end'] = prepre_mon_select['report_next_end'] - pd.DateOffset(months=2)\n",
    "\n",
    "class_0_all_target_df = pd.concat(\n",
    "                        [premon_select, \n",
    "                         prepre_mon_select]).set_index(['client_id', 'report_next_end'])\n",
    "class_0_all_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182247, 66)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_1_all_target_df = class_1_all_target_df.set_index(['client_id', 'report_next_end'])\n",
    "class_1_all_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((211174, 66), (182247, 66))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_0_all_target_df.shape, class_1_all_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211174, 66)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_train_target_df = sub_train_target_df.set_index(['client_id', 'report_next_end'])\n",
    "class_0_all_target_df = sub_train_target_df[\n",
    "        (sub_train_target_df.index.isin(class_0_all_target_df.index))&\n",
    "        (sub_train_target_df['is_target'] != 1)\n",
    "]\n",
    "class_0_all_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118361, 66)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Подмешиваем случайных пользователей, которые и никогда не покупали продукт\n",
    "# sub_train_target_df\n",
    "random_0_class_df = sub_train_target_df[sub_train_target_df['is_target'] == 0].sample(30_000)\n",
    "class_0_all_target_df = pd.concat([class_0_all_target_df, random_0_class_df])\n",
    "class_0_all_target_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0_all_target_df.values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518520, 66)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Возвращаем тест и вал пользователей\n",
    "# class_1_target_1 = pd.concat([class_1_target_1, class_0_all_target_df])\n",
    "sub_train_target_df = train_target_df.copy()\n",
    "sub_train_target_df = sub_train_target_df.reset_index()\n",
    "sub_train_target_df = sub_train_target_df[(\n",
    "    (sub_train_target_df['client_id'].isin(val_clients_df['client_id']))|\n",
    "    (sub_train_target_df['client_id'].isin(test_clients_df['client_id']))\n",
    ")]\n",
    "sub_train_target_df = sub_train_target_df.set_index(['client_id', 'report_next_end'])\n",
    "\n",
    "sub_train_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(711725, 66)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Формируем итоговый датасет вместе с итоговым сэмплем и вместе с тест и вал пользователями \n",
    "result_sample_train_target_df = pd.concat([class_1_all_target_df, class_0_all_target_df, sub_train_target_df])\n",
    "result_sample_train_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(711725, 66)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_df = result_sample_train_target_df\n",
    "train_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Первая версия сэмлера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_random_undersampling(df:pd.DataFrame, target_col:str, desired_ratio:float):\n",
    "#     \"\"\"\n",
    "#     Кастомный RandomUnderSampling, с указанием доли распредления desired_ratio.\n",
    "    \n",
    "#     df: исходный DataFrame.\n",
    "#     target_col: название столбца с целевой переменной.\n",
    "#     desired_ratio: желаемое соотношение меньшего класса к большему классу (между 0 и 1).\n",
    "    \n",
    "#     return: под-выборка исходного DataFrame с заданным соотношением классов.\n",
    "#     \"\"\"\n",
    "#     # Получаем распределение классов в исходном DataFrame\n",
    "#     class_counts = Counter(df[target_col])\n",
    "    \n",
    "#     # Определяем меньший и больший классы\n",
    "#     minority_class = min(class_counts, key=class_counts.get)\n",
    "#     majority_class = max(class_counts, key=class_counts.get)\n",
    "    \n",
    "#     # Вычисляем желаемое количество примеров меньшего класса\n",
    "#     minority_count = class_counts[minority_class]\n",
    "#     majority_count = int(minority_count / desired_ratio)\n",
    "    \n",
    "#     # Создаем под-выборки для меньшего и большего классов\n",
    "#     minority_subset = df[df[target_col] == minority_class]\n",
    "#     majority_subset = resample(df[df[target_col] == majority_class],\n",
    "#                                replace=False,\n",
    "#                                n_samples=majority_count,\n",
    "#                                random_state=53)\n",
    "    \n",
    "#     # Объединяем под-выборки и сохраняем исходный индекс\n",
    "#     resampled_df = pd.concat([minority_subset, majority_subset], ignore_index=False)\n",
    "    \n",
    "#     return resampled_df\n",
    "\n",
    "# train_target_df = custom_random_undersampling(train_target_df, 'is_target', desired_ratio=0.5)\n",
    "# train_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
