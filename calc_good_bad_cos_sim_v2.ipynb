{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Рассчитываем хорошие и плохие вектора и близость до них"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Цель: предсказать для каждого пользователя взятие/ невзятие каждого из четырех продуктов **в течение месяца после отчетной даты**, исторические данные по ним находятся в targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_float_dtype, is_integer_dtype\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import math\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import gc\n",
    "import glob\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# найтройки\n",
    "# Убираем ограничение отображемых колонок\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# Устанавливаем тему по умолчанию\n",
    "sb_dark = sns.dark_palette('skyblue', 8, reverse=True) # teal\n",
    "sns.set(palette=sb_dark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Включаем tqdm для pandas, чтобы можно было запускать progress_apply() вместо простого apply()\n",
    "tqdm.pandas() \n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PATH = ''\n",
    "PATH_DATASET = PATH + 'datasets/sber_source/'\n",
    "PATH_DATASET_OUTPUT = PATH + 'datasets/'\n",
    "\n",
    "PATH_DATASET_DIALOG_TRAIN = PATH_DATASET + 'dial_train.parquet/'\n",
    "PATH_DATASET_DIALOG_TEST = PATH_DATASET + 'dial_test.parquet/'\n",
    "\n",
    "PATH_DATASET_TARGET_TRAIN = PATH_DATASET + 'train_target.parquet/'\n",
    "PATH_DATASET_TARGET_TEST = PATH_DATASET + 'test_target_b.parquet/'\n",
    "\n",
    "\n",
    "# dialogs\n",
    "train_dialog_files = glob.glob(PATH_DATASET_DIALOG_TRAIN + '/*.parquet')\n",
    "test_dialog_files = glob.glob(PATH_DATASET_DIALOG_TEST + '/*.parquet')\n",
    "\n",
    "# Файлы таргеты\n",
    "train_target_files = glob.glob(PATH_DATASET_TARGET_TRAIN + '/*.parquet')\n",
    "test_target_files = glob.glob(PATH_DATASET_TARGET_TEST + '/*.parquet')\n",
    "\n",
    "\n",
    "len(train_dialog_files), len(test_dialog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка списка файлов (типа паркет) в один датафрейм\n",
    "def load_df_by_files(files:list[str]) -> pd.DataFrame:\n",
    "    union_df = pd.DataFrame()\n",
    "    for file in tqdm(files):\n",
    "        current_df = pq.read_table(file).to_pandas()    \n",
    "        union_df = pd.concat([union_df, current_df])\n",
    "    return union_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Загружаем все таргеты\n",
    "all_target_df = load_df_by_files(train_target_files + test_target_files)\n",
    "all_target_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Диалоги Рассчитываем хорошие и плохие вектора и близость до них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dial_select_1_df = pq.read_table(PATH_DATASET_OUTPUT + 'embeddings/' + 'emb_dial_v6.1_K-Means.parquet').to_pandas()\n",
    "emb_dial_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dial_select_1_df = emb_dial_select_1_df.rename(columns={'emb_trx': 'embedding'})\n",
    "emb_dial_select_1_df = emb_dial_select_1_df.drop(columns=['year', 'event_time', 'mon', 'target_1', 'target_2', 'target_3', 'target_4'], errors='ignore')\n",
    "emb_dial_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dial_select_1_df['report_next_end'] = pd.to_datetime(emb_dial_select_1_df['report_next_end'])\n",
    "emb_dial_select_1_df = emb_dial_select_1_df.set_index(['client_id', 'report_next_end'])\n",
    "emb_dial_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рассчитываем хорошие и плохие диалоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_target_df['mon'] = pd.to_datetime(all_target_df['mon'])\n",
    "all_target_df = all_target_df.rename(columns={'mon': 'report_next_end'})\n",
    "all_target_df = all_target_df.set_index(['client_id', 'report_next_end'])\n",
    "all_target_df['is_target'] = all_target_df[['target_1', 'target_2', 'target_3', 'target_4']].max(axis=1)\n",
    "all_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dial_select_1_df = all_target_df.merge(emb_dial_select_1_df, left_index=True, right_index=True)\n",
    "emb_dial_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emb_dial_select_1_df = emb_dial_select_1_df.drop(columns=['target_1', 'target_2', 'target_3', 'target_4', 'is_target', 'embedding'], errors='ignore')\n",
    "emb_dial_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dial_select_1_df = emb_dial_select_1_df.add_prefix('geo_emb_v2__')\n",
    "emb_dial_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Сохраняем статистику по косинусной близости\n",
    "emb_dial_select_1_df.to_parquet(PATH_DATASET_OUTPUT + 'good_bad_dialog_target_df_v2_16_06_2024.parquet')\n",
    "emb_dial_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ГЕО Рассчитываем хорошие и плохие вектора и близость до них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_emb_select_1_df = pq.read_table(PATH_DATASET_OUTPUT + 'embeddings/' + 'geo_emb_select_1_v3_K-Means.parquet').to_pandas()\n",
    "geo_emb_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_emb_select_1_df = geo_emb_select_1_df.rename(columns={'emb_trx': 'embedding'})\n",
    "geo_emb_select_1_df = geo_emb_select_1_df.drop(columns=['year', 'event_time', 'mon', 'target_1', 'target_2', 'target_3', 'target_4'], errors='ignore')\n",
    "geo_emb_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_emb_select_1_df['report_next_end'] = pd.to_datetime(geo_emb_select_1_df['report_next_end'])\n",
    "geo_emb_select_1_df = geo_emb_select_1_df.set_index(['client_id', 'report_next_end'])\n",
    "geo_emb_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рассчитываем хорошие и плохие диалоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_target_df['mon'] = pd.to_datetime(all_target_df['mon'])\n",
    "all_target_df = all_target_df.rename(columns={'mon': 'report_next_end'})\n",
    "all_target_df = all_target_df.set_index(['client_id', 'report_next_end'])\n",
    "all_target_df['is_target'] = all_target_df[['target_1', 'target_2', 'target_3', 'target_4']].max(axis=1)\n",
    "all_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_emb_select_1_df = all_target_df.merge(geo_emb_select_1_df, left_index=True, right_index=True)\n",
    "geo_emb_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Считаем \"хорошие\" и \"плохие\" эмбеддинги\n",
    "target_columns = ['target_1', 'target_2', 'target_3', 'target_4', 'is_target']\n",
    "\n",
    "target_embeddings_dict ={}\n",
    "dialog_embeddings = np.vstack(geo_emb_select_1_df['embedding'].apply(np.array).values)\n",
    "\n",
    "for trg_col in target_columns:\n",
    "    print(trg_col)\n",
    "    \n",
    "    good_sub_dlg_trg_df = geo_emb_select_1_df[geo_emb_select_1_df[trg_col] == 1]\n",
    "    bad_sub_dlg_trg_df = geo_emb_select_1_df[geo_emb_select_1_df[trg_col] == 0]\n",
    "    good_embedding = good_sub_dlg_trg_df['embedding'].mean()\n",
    "    bad_embedding = bad_sub_dlg_trg_df['embedding'].mean()\n",
    "    \n",
    "    target_embeddings_dict[trg_col] = {}\n",
    "    target_embeddings_dict[trg_col]['good'] = good_embedding\n",
    "    target_embeddings_dict[trg_col]['bad'] = bad_embedding\n",
    "    \n",
    "    # Производим расчет косинусного расстояния\n",
    "    geo_emb_select_1_df[f'cos_sim_{trg_col}_good'] = cosine_similarity(dialog_embeddings, good_embedding[None])\n",
    "    geo_emb_select_1_df[f'cos_sim_{trg_col}_bad'] = cosine_similarity(dialog_embeddings, bad_embedding[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет статистик на данных\n",
    "good_columns = []\n",
    "bad_columns = []\n",
    "for trg_col in target_columns:\n",
    "    print(trg_col)\n",
    "    good_col = f'cos_sim_{trg_col}_good'\n",
    "    bad_col = f'cos_sim_{trg_col}_bad'\n",
    "    good_columns.append(good_col)\n",
    "    bad_columns.append(bad_col)\n",
    "    \n",
    "    geo_emb_select_1_df['dist_bad_good'] = abs(geo_emb_select_1_df[bad_col] - geo_emb_select_1_df[good_col])\n",
    "    geo_emb_select_1_df['diff_bad_good'] = geo_emb_select_1_df[bad_col] - geo_emb_select_1_df[good_col]\n",
    "    geo_emb_select_1_df['rel_bad_good'] = geo_emb_select_1_df[bad_col] / (geo_emb_select_1_df[good_col] + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in ['bad', 'good']:\n",
    "    geo_emb_select_1_df[f'mean_{t}_cossim'] = geo_emb_select_1_df[bad_columns].mean(axis=1)\n",
    "    geo_emb_select_1_df[f'max_{t}_cossim'] = geo_emb_select_1_df[bad_columns].max(axis=1)\n",
    "    geo_emb_select_1_df[f'min_{t}_cossim'] = geo_emb_select_1_df[bad_columns].min(axis=1)\n",
    "    geo_emb_select_1_df[f'sum_{t}_cossim'] = geo_emb_select_1_df[bad_columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geo_emb_select_1_df = geo_emb_select_1_df.drop(columns=['target_1', 'target_2', 'target_3', 'target_4', 'is_target', 'embedding'])\n",
    "geo_emb_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_emb_select_1_df = geo_emb_select_1_df.add_prefix('geo_emb__')\n",
    "geo_emb_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Сохраняем статистику по косинусной близости\n",
    "# geo_emb_select_1_df.to_parquet(PATH_DATASET_OUTPUT + 'good_bad_geo_target_df_16_06_2024.parquet')\n",
    "# geo_emb_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Транзакции Рассчитываем хорошие и плохие вектора и близость до них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trx_emb_select_1_df = pq.read_table(PATH_DATASET_OUTPUT + 'embeddings/' + 'trx_emb_select_1_v3_K-Means.parquet').to_pandas()\n",
    "trx_emb_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trx_emb_select_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trx_emb_select_1_df = trx_emb_select_1_df.rename(columns={'emb_trx': 'embedding'})\n",
    "trx_emb_select_1_df = trx_emb_select_1_df.drop(columns=['year', 'event_time', 'mon', 'target_1', 'target_2', 'target_3', 'target_4'], errors='ignore')\n",
    "trx_emb_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trx_emb_select_1_df['report_next_end'] = pd.to_datetime(trx_emb_select_1_df['report_next_end'])\n",
    "trx_emb_select_1_df = trx_emb_select_1_df.set_index(['client_id', 'report_next_end'])\n",
    "trx_emb_select_1_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рассчитываем хорошие и плохие диалоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_target_df['mon'] = pd.to_datetime(all_target_df['mon'])\n",
    "all_target_df = all_target_df.rename(columns={'mon': 'report_next_end'})\n",
    "all_target_df = all_target_df.set_index(['client_id', 'report_next_end'])\n",
    "all_target_df['is_target'] = all_target_df[['target_1', 'target_2', 'target_3', 'target_4']].max(axis=1)\n",
    "all_target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trx_emb_select_1_df = all_target_df.merge(trx_emb_select_1_df, left_index=True, right_index=True)\n",
    "trx_emb_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Считаем \"хорошие\" и \"плохие\" эмбеддинги\n",
    "target_columns = ['target_1', 'target_2', 'target_3', 'target_4', 'is_target']\n",
    "\n",
    "target_embeddings_dict ={}\n",
    "dialog_embeddings = np.vstack(trx_emb_select_1_df['embedding'].apply(np.array).values)\n",
    "\n",
    "for trg_col in target_columns:\n",
    "    print(trg_col)\n",
    "    \n",
    "    good_sub_dlg_trg_df = trx_emb_select_1_df[trx_emb_select_1_df[trg_col] == 1]\n",
    "    bad_sub_dlg_trg_df = trx_emb_select_1_df[trx_emb_select_1_df[trg_col] == 0]\n",
    "    good_embedding = good_sub_dlg_trg_df['embedding'].mean()\n",
    "    bad_embedding = bad_sub_dlg_trg_df['embedding'].mean()\n",
    "    \n",
    "    target_embeddings_dict[trg_col] = {}\n",
    "    target_embeddings_dict[trg_col]['good'] = good_embedding\n",
    "    target_embeddings_dict[trg_col]['bad'] = bad_embedding\n",
    "    \n",
    "    # Производим расчет косинусного расстояния\n",
    "    trx_emb_select_1_df[f'cos_sim_{trg_col}_good'] = cosine_similarity(dialog_embeddings, good_embedding[None])\n",
    "    trx_emb_select_1_df[f'cos_sim_{trg_col}_bad'] = cosine_similarity(dialog_embeddings, bad_embedding[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет статистик на данных\n",
    "good_columns = []\n",
    "bad_columns = []\n",
    "for trg_col in target_columns:\n",
    "    print(trg_col)\n",
    "    good_col = f'cos_sim_{trg_col}_good'\n",
    "    bad_col = f'cos_sim_{trg_col}_bad'\n",
    "    good_columns.append(good_col)\n",
    "    bad_columns.append(bad_col)\n",
    "    \n",
    "    trx_emb_select_1_df['dist_bad_good'] = abs(trx_emb_select_1_df[bad_col] - trx_emb_select_1_df[good_col])\n",
    "    trx_emb_select_1_df['diff_bad_good'] = trx_emb_select_1_df[bad_col] - trx_emb_select_1_df[good_col]\n",
    "    trx_emb_select_1_df['rel_bad_good'] = trx_emb_select_1_df[bad_col] / (trx_emb_select_1_df[good_col] + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in ['bad', 'good']:\n",
    "    trx_emb_select_1_df[f'mean_{t}_cossim'] = trx_emb_select_1_df[bad_columns].mean(axis=1)\n",
    "    trx_emb_select_1_df[f'max_{t}_cossim'] = trx_emb_select_1_df[bad_columns].max(axis=1)\n",
    "    trx_emb_select_1_df[f'min_{t}_cossim'] = trx_emb_select_1_df[bad_columns].min(axis=1)\n",
    "    trx_emb_select_1_df[f'sum_{t}_cossim'] = trx_emb_select_1_df[bad_columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trx_emb_select_1_df = trx_emb_select_1_df.drop(columns=['target_1', 'target_2', 'target_3', 'target_4', 'is_target', 'embedding'])\n",
    "trx_emb_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trx_emb_select_1_df = trx_emb_select_1_df.add_prefix('trx_emb__')\n",
    "trx_emb_select_1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trx_emb_select_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Диалоги Рассчитываем хорошие и плохие вектора и близость до них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Загружаем диалоги клиентов\n",
    "# train_dialog_df = load_df_by_files(train_dialog_files)\n",
    "# test_dialog_df = load_df_by_files(test_dialog_files)\n",
    "# train_dialog_df.shape, test_dialog_df.shape\n",
    "# all_dialogs_df = pd.concat([train_dialog_df, test_dialog_df])\n",
    "all_dialogs_df = load_df_by_files(train_dialog_files + test_dialog_files)\n",
    "all_dialogs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "all_dialogs_df['end_month'] = pd.to_datetime(all_dialogs_df['event_time'], format=\"%Y%m\") + MonthEnd(1)\n",
    "all_dialogs_df['end_month'] = all_dialogs_df['end_month'].dt.date\n",
    "all_dialogs_df['report_next_end'] = all_dialogs_df['end_month'] + relativedelta(months=1)\n",
    "all_dialogs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_dialogs_df = all_dialogs_df[:1000]\n",
    "all_dialogs_df = all_dialogs_df.drop(columns=['event_time', 'end_month'], errors='ignore')\n",
    "all_dialogs_df['report_next_end'] = pd.to_datetime(all_dialogs_df['report_next_end'])\n",
    "all_dialogs_df = all_dialogs_df.set_index(['client_id', 'report_next_end'])\n",
    "all_dialogs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # end_date = start_date + relativedelta(months=1) - relativedelta(days=1)\n",
    "# # report_next_end\n",
    "# all_dialogs_df['end_month'] + relativedelta(months=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рассчитываем хорошие и плохие диалоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_target_df['mon'] = pd.to_datetime(all_target_df['mon'])\n",
    "all_target_df = all_target_df.rename(columns={'mon': 'report_next_end'})\n",
    "all_target_df = all_target_df.set_index(['client_id', 'report_next_end'])\n",
    "all_target_df['is_target'] = all_target_df[['target_1', 'target_2', 'target_3', 'target_4']].max(axis=1)\n",
    "all_target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogs_target_df = all_target_df.merge(all_dialogs_df, left_index=True, right_index=True)\n",
    "dialogs_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Считаем \"хорошие\" и \"плохие\" эмбеддинги\n",
    "target_columns = ['target_1', 'target_2', 'target_3', 'target_4', 'is_target']\n",
    "\n",
    "target_embeddings_dict ={}\n",
    "dialog_embeddings = np.vstack(dialogs_target_df['embedding'].apply(np.array).values)\n",
    "\n",
    "for trg_col in target_columns:\n",
    "    print(trg_col)\n",
    "    \n",
    "    good_sub_dlg_trg_df = dialogs_target_df[dialogs_target_df[trg_col] == 1]\n",
    "    bad_sub_dlg_trg_df = dialogs_target_df[dialogs_target_df[trg_col] == 0]\n",
    "    good_embedding = good_sub_dlg_trg_df['embedding'].mean()\n",
    "    bad_embedding = bad_sub_dlg_trg_df['embedding'].mean()\n",
    "    \n",
    "    target_embeddings_dict[trg_col] = {}\n",
    "    target_embeddings_dict[trg_col]['good'] = good_embedding\n",
    "    target_embeddings_dict[trg_col]['bad'] = bad_embedding\n",
    "    \n",
    "    # Производим расчет косинусного расстояния\n",
    "    dialogs_target_df[f'cos_sim_{trg_col}_good'] = cosine_similarity(dialog_embeddings, good_embedding[None])\n",
    "    dialogs_target_df[f'cos_sim_{trg_col}_bad'] = cosine_similarity(dialog_embeddings, bad_embedding[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет статистик на данных\n",
    "good_columns = []\n",
    "bad_columns = []\n",
    "for trg_col in target_columns:\n",
    "    print(trg_col)\n",
    "    good_col = f'cos_sim_{trg_col}_good'\n",
    "    bad_col = f'cos_sim_{trg_col}_bad'\n",
    "    good_columns.append(good_col)\n",
    "    bad_columns.append(bad_col)\n",
    "    \n",
    "    dialogs_target_df['dist_bad_good'] = abs(dialogs_target_df[bad_col] - dialogs_target_df[good_col])\n",
    "    dialogs_target_df['diff_bad_good'] = dialogs_target_df[bad_col] - dialogs_target_df[good_col]\n",
    "    dialogs_target_df['rel_bad_good'] = dialogs_target_df[bad_col] / (dialogs_target_df[good_col] + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in ['bad', 'good']:\n",
    "    dialogs_target_df[f'mean_{t}_cossim'] = dialogs_target_df[bad_columns].mean(axis=1)\n",
    "    dialogs_target_df[f'max_{t}_cossim'] = dialogs_target_df[bad_columns].max(axis=1)\n",
    "    dialogs_target_df[f'min_{t}_cossim'] = dialogs_target_df[bad_columns].min(axis=1)\n",
    "    dialogs_target_df[f'sum_{t}_cossim'] = dialogs_target_df[bad_columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dialogs_target_df = dialogs_target_df.drop(columns=['target_1', 'target_2', 'target_3', 'target_4', 'is_target', 'embedding'])\n",
    "dialogs_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogs_target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Сохраняем статистику по косинусной близости\n",
    "# dialogs_target_df.to_parquet(PATH_DATASET_OUTPUT + 'good_bad_dialogs_target_df_16_06_2024.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем языковую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bertmodel = SentenceTransformer('DeepPavlov/bart-base-en-persona-chat') # 768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формируем примеры диалогов по тематикам \n",
    "На базе https://claude.ai/  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dialogs = {\"Текущие (расчетные) счета\": [\n",
    "    {\"Позитивный диалог:\": \"Клиент: Здравствуйте, я бы хотел открыть расчетный счет в вашем банке для своего бизнеса. Оператор: Хорошо, для этого вам необходимо предоставить следующие документы: свидетельство о регистрации юридического лица, устав, приказ о назначении директора и другие учредительные документы. После их рассмотрения мы сможем открыть вам расчетный счет. Клиент: Отлично, большое спасибо за подробную информацию. Я соберу все необходимые документы и приду в ближайшее отделение.\"},\n",
    "    {\"Негативный диалог:\": \"Клиент: Я уже несколько раз обращался с просьбой открыть расчетный счет, но каждый раз мне говорят о новых требованиях к документам! Это издевательство! Оператор: Извините, но мы обязаны соблюдать требования законодательства и внутренних нормативов банка. Возможно, есть какие-то нюансы в вашей ситуации, и поэтому запрашиваются дополнительные документы. Давайте разберемся подробнее, что именно вам требуется?\",},\n",
    "],\n",
    "\"Депозиты (вклады)\": [\n",
    "    {\"Позитивный диалог:\": \"Клиент: Добрый день, какие виды вкладов сейчас наиболее выгодные в вашем банке? Оператор: Здравствуйте. Сейчас наиболее привлекательными являются наши накопительные вклады со ставкой до 7% годовых. Вы можете открыть его с минимальной суммой от 50 000 рублей. Также есть возможность частичного снятия средств без потери процентов.Клиент: Отлично, тогда я бы хотел открыть такой вклад. Скажите, пожалуйста, какие документы нужно принести в отделение?\"},\n",
    "    {\"Негативный диалог:\": \"Клиент: Я открыл вклад в вашем банке 3 месяца назад под 9% годовых. А сегодня вижу, что ставки снизились до 7%. Почему мне не предложили более выгодные условия?Оператор: К сожалению, условия по вкладам фиксируются на момент их открытия и действуют до окончания срока. Изменить ставку на более высокую в течение срока вклада невозможно.Клиент: Это некрасиво по отношению к постоянным клиентам банка! Вы должны ценить нас и предлагать лучшие условия!\"},\n",
    "],\n",
    "\"Кредиты\": [\n",
    "    {\"Позитивный диалог:\": \"Клиент: Здравствуйте, я недавно обращался за кредитом в ваш банк. Могу я узнать, на каком этапе рассмотрения моя заявка?Оператор: Да, конечно. Позвольте уточнить ваши персональные данные... Хорошо, ваша заявка уже одобрена. В ближайшие 2 дня с вами свяжется наш менеджер для дальнейшего оформления кредитной документации.Клиент: Отлично, большое спасибо за оперативность. Буду ждать звонка менеджера.\"},\n",
    "    {\"Негативный диалог:\": \"Клиент: Я крайне разочарован работой вашего банка! Мне отказали в кредите, хотя все требования были соблюдены. При этом никаких внятных объяснений не предоставили.Оператор: Сожалею, что у вас сложилось негативное впечатление. Решение об одобрении или отказе выносится на основании тщательного анализа кредитоспособности клиента и опирается на ряд факторов. Я проверю вашу ситуацию и дам более развернутый ответ.\"},\n",
    "],\n",
    "\"Кредитные карты\": [\n",
    "    {\"Позитивный диалог:\": \"Клиент: Добрый день, я бы хотел оформить кредитную карту. Какие условия сейчас действуют? Оператор: Здравствуйте. У нас сейчас очень выгодное предложение - кредитная карта с льготным периодом 100 дней без процентов на все покупки. Также есть начисление баллов за покупки, которые можно обменивать на подарки. Клиент: Отличное предложение! Скажите, какие документы нужно предоставить для оформления? Оператор: Для получения карты понадобятся паспорт, справка о доходах и анкета, которую можно заполнить у нас в отделении.\"},\n",
    "    {\"Негативный диалог:\": \"Клиент: Добрый день, моя кредитная карта вашего банка заблокирована уже несколько дней без объяснения причин! Требую разъяснить ситуацию! Оператор: Сожалею, ваша кредитная карта действительно была временно заблокирована нашей службой безопасности по причине подозрительной операции. Мы проводили дополнительную проверку, чтобы убедиться, что карта не была использована третьими лицами. Клиент: Это недопустимо! У меня были запланированы важные покупки, а из-за ваших необоснованных действий я понес убытки!\"},\n",
    "],\n",
    "\"Дебетовые карты\": [\n",
    "    {\"Позитивный диалог:\": \"Клиент: Здравствуйте, я хотел бы открыть вклад и оформить к нему дебетовую карту. Оператор: Хорошо, конечно. Вы можете выбрать подходящий вклад на нашем сайте в разделе 'Вклады и инвестиции'. Затем, открыв вклад, вы сможете сразу же оформить и получить дебетовую карту к нему для удобного управления средствами. Клиент: Отлично, спасибо за информацию. Я изучу предложения и открою вклад в ближайшее время.\"},\n",
    "    {\"Негативный диалог:\": \"Клиент: Добрый день! Моя зарплатная карта вашего банка была украдена, и с нее сняли все деньги. Почему средства не заблокированы своевременно? Оператор: Сожалею, что такая неприятная ситуация произошла. Для блокировки карты вам необходимо было незамедлительно обратиться в банк после кражи. Без вашего оповещения мы не могли знать о несанкционированных действиях с картой. Клиент: Но служба поддержки совершенно недоступна по вечерам и в выходные! Как клиент мог оперативно\"},\n",
    "],\n",
    "\"Денежные переводы и платежи (внутренние и международные)\": [\n",
    "    {\"Позитивный диалог:\": \"Клиент: Здравствуйте, мне нужно срочно перевести деньги родственникам за границу. Подскажите, как это можно сделать? Оператор: Здравствуйте. Для отправки денежного перевода за рубеж вам необходимо посетить любое отделение нашего банка и оформить международный перевод. Понадобится указать получателя, его реквизиты, сумму и валюту перевода. Комиссия будет зависеть от суммы и выбранной системы перевода. Клиент: Хорошо, спасибо большое за информацию. Тогда я приеду в ближайшее отделение и оформлю перевод.\"},\n",
    "    {\"Негативный диалог:\": \"Клиент: Я делал платеж через ваш интернет-банкинг на прошлой неделе, но деньги до сих пор не дошли получателю! Что за задержки? Оператор: Сожалею за доставленные неудобства. Для выяснения ситуации мне необходимо уточнить реквизиты платежа и способ его отправки. Переводы внутри страны обычно проходят в течение 1-2 рабочих дней. Клиент: Это просто безобразие! Я должен был оплатить важную услугу вовремя. Требую немедленного зачисления средств получателю и компенсации за задержку!\"},\n",
    "],\n",
    "\"Инвестиционные продукты (брокерские услуги, ПИФы, доверительное управление)\": [\n",
    "    {\"Позитивный диалог:\": \"Клиент: Добрый день! Меня заинтересовали ваши инвестиционные услуги. Не могли бы вы рассказать подробнее о паевых инвестиционных фондах? Оператор: Конечно. ПИФы - это очень удобный инструмент для вложения средств под управлением профессиональной команды. У нас есть разные типы ПИФов: акций, облигаций, смешанных и других стратегий на выбор в зависимости от ваших инвестиционных целей и предпочтений по риску. Минимальная сумма покупки пая от 10 000 руб. Клиент: Хорошо, спасибо. Я изучу линейку ваших ПИФов и приму решение о покупке пая в ближайшее время.\"},\n",
    "    {\"Негативный диалог:\": \"Клиент: Я доверил вашим специалистам управление своим портфелем акций, а он принес убытки за год! Верну ли я свои вложенные средства? Оператор: Сожалею, что сложилась такая ситуация. Ввиду волатильности на рынках невозможно гарантировать прибыльность инвестиционного портфеля в краткосрочной перспективе. Но наши управляющие придерживаются разработанной стратегии, чтобы минимизировать риски. Клиент: Это неприемлемо! Я ожидал защиты моих средств, а не таких потерь. Прошу вернуть мои вложения в полном объеме!\"},\n",
    "],\n",
    "\"Банковские гарантии и аккредитивы\": [\n",
    "    {\"Позитивный диалог:\": \"Клиент: Здравствуйте, мне необходимо получить банковскую гарантию для обеспечения контракта. Каковы условия предоставления гарантий в вашем банке? Оператор: Для оформления гарантии нам потребуются учредительные документы вашей организации, финансовая отчетность, информация о контракте и обеспечении. После рассмотрения документов мы сможем назвать точные условия: сумму, сроки, тарифы. Клиент: Хорошо, большое спасибо. Я соберу пакет документов и приеду в ближайшее отделение для дальнейшего оформления.\"},\n",
    "    {\"Негативный диалог:\": \"Клиент: Вы уже месяц рассматриваете нашу заявку на получение аккредитива для расчетов с поставщиком. Сроки контракта горят! Почему так долго? Оператор: Извините за причиненные неудобства. Процедура рассмотрения аккредитивов более длительная, так как требует глубокого анализа контрактов и предполагаемых сделок на предмет экономических рисков. Мы стараемся максимально ускориться. Клиент: Это недопустимая волокита! Из-за ваших проволочек мы можем понести репутационные и финансовые потери. Прошу принять наконец положительное решение по нашему аккредитиву!\"},\n",
    "],\n",
    "\"Услуги инкассации и хранения ценностей\": [\n",
    "    {\"Позитивный диалог:\": \"Клиент: Добрый день! Наша компания хотела бы воспользоваться услугами инкассации для перевозки наличных средств из торговых точек. Расскажите, пожалуйста, как мы можем это организовать? Оператор: Хорошо, для организации инкассаторских услуг вам необходимо заключить с нами договор. Сначала нужно предоставить пакет документов о компании, указать адреса забора и сумки. После этого мы составим маршрут и графики инкассации. Клиент: Отлично, большое спасибо за информацию. В ближайшее время наш специалист свяжется с вами для оформления договора.\"},\n",
    "    {\"Негативный диалог:\": \"Клиент: Добрый день! Я крайне возмущен работой вашей инкассаторской службы. Уже второй раз за месяц происходит задержка при вывозе наличных из наших магазинов! Оператор: Сожалею за доставленные неудобства. Такие ситуации недопустимы. Прошу прощения за сложившуюся ситуацию. Обязательно разберемся в причинах задержек и примем необходимые меры. Клиент: Это полное безобразие! Из-за подобных простоев мы несем финансовые потери. Прошу принять жесткие меры к исполнителям и гарантировать своевременное обслуживание по договору!\"},\n",
    "],\n",
    "\"Зарплатные проекты для организаций\": [\n",
    "    {\"Позитивный диалог:\": \"Клиент: Здравствуйте, меня интересует возможность перевода сотрудников нашей компании на зарплатный проект с вашим банком. Не могли бы вы рассказать об условиях и преимуществах? Оператор: Да, с удовольствием. Наш зарплатный проект предлагает ряд выгод как для вашей организации, так и для сотрудников. Для компании - это упрощение процедуры выплат зарплат, снижение издержек на обслуживание и специальные тарифы на РКО. Для сотрудников - бесплатное открытие и обслуживание карт, повышенный кэшбэк, льготные ставки по кредитам. Клиент: Звучит заманчиво. Расскажите, как можно подключиться к зарплатному проекту? Оператор: Для этого необходимо заключить договор зарплатного проекта с банком. Вам понадобится предоставить пакет учредительных документов компании, и мы рассмотрим заявку в короткие сроки.\"},\n",
    "    {\"Негативный диалог:\": \"Клиент: Я крайне недоволен вашим зарплатным обслуживанием! Уже третий месяц наши сотрудники жалуются на задержки зарплатных выплат. Это недопустимо! Оператор: Приношу свои извинения за доставленные неудобства. Это недопустимая ситуация, я обязательно разберусь в причинах задержек и передам информацию руководству для принятия мер. Клиент: Ваши извинения ничего не стоят! Из-за ваших постоянных сбоев мы рискуем потерять ценные кадры. Если ситуация не изменится, мы будем вынуждены отказаться от ваших услуг!\"},\n",
    "],\n",
    "\"Приложение банка\": [\n",
    "    {\"Позитивный диалог:\": \"Клиент: Добрый день! Хотел узнать, есть ли у вашего банка мобильное приложение для управления счетами и картами? Оператор: Да, конечно. Мы разработали удобное мобильное приложение, которое позволяет полностью управлять вашими финансами удаленно. В приложении можно совершать переводы, погашать кредиты, пополнять вклады, анализировать расходы и многое другое. Клиент: Здорово! А как его можно установить? Оператор: Приложение доступно для скачивания в Play Market и App Store. После установки вам нужно будет пройти несложную регистрацию и авторизоваться, используя те же логин и пароль, что и в интернет-банке.\"},\n",
    "    {\"Негативный диалог:\": \"Клиент: Вашим мобильным приложением совершенно невозможно пользоваться - оно постоянно зависает и вылетает! Это ужасно! Оператор: Сожалею, что приложение доставляет вам неудобства. Мы стараемся постоянно совершенствовать его производительность и устранять замеченные недочеты. Не могли бы вы подробнее описать проблему? Это поможет разработчикам оперативно найти и исправить причину сбоев. Клиент: Да что тут описывать! Оно просто не работает нормально. То покупки не проходят, то платежи, то выдает ошибку при входе. Лучше полностью переделывайте приложение!\"},\n",
    "],\n",
    "\"Автокредиты\": [\n",
    "    {\"Позитивный диалог:\": \"Клиент: Здравствуйте, меня интересуют условия автокредитования в вашем банке. Я хотел бы приобрести новую машину в кредит. Оператор: Хорошо, для покупки нового автомобиля мы можем предложить вам выгодную программу автокредитования. Максимальный срок - 5 лет, ставка от 7,9% годовых, первоначальный взнос от 20%. Также предусмотрены программы с остаточным платежом и без первого взноса. Клиент: Замечательно, спасибо. А какие документы понадобятся для оформления кредита? Оператор: Для получения автокредита необходим паспорт, водительское удостоверение и справка о доходах. При визите в отделение наш менеджер сможет помочь собрать полный пакет документов.\"},\n",
    "    {\"Негативный диалог:\": \"Клиент: Я крайне возмущен работой вашего банка! Мне одобрили автокредит под гораздо более высокую ставку, чем та, что озвучивалась при рекламе вашего предложения. Оператор: Сожалею, что у вас сложилось негативное впечатление. В рекламных материалах мы указываем максимально низкие ставки, действующие только для наиболее надежных клиентов с идеальной кредитной историей. Конечретные условия определяются индивидуально после рассмотрения заявки. Клиент: Это недобросовестная реклама! Вы вводите клиентов в заблуждение. Отказываюсь от вашего кредита и буду жаловаться в надзорные органы!\"},\n",
    "],\n",
    "\"Кэшбэк\": [\n",
    "    {\"Позитивный диалог:\": \"Клиент: Здравствуйте, я пользуюсь вашей кредитной картой с начислением кэшбэка. Подскажите, как можно получить накопленный кэшбэк? Оператор: Приветствую! Для получения средств, накопленных по программе кэшбэка, вам нужно зайти в личный кабинет на сайте или в мобильном приложении. В разделе 'Бонусы и кэшбэк' будет указана доступная сумма для вывода на ваш счет или карту. Оформите заявку, и деньги будут зачислены в течение 3-5 рабочих дней. Клиент: Понятно, большое спасибо за разъяснение! Воспользуюсь личным кабинетом.\"},\n",
    "    {\"Негативный диалог:\": \"Клиент: Добрый день! Хочу высказать претензию по использованию вашей рекламной акции с кэшбэком. Мне вернули только половину обещанной суммы! Оператор: Сожалею, что возникло такое недопонимание. Давайте уточним условия акции, при которых вы рассчитывали на определенную сумму кэшбэка. Возможно, часть покупок не подпадала под действие акционного предложения согласно ограничени\"}, \n",
    "]\n",
    "}\n",
    "\n",
    "ru_en_cat_names = {\"Текущие (расчетные) счета\": \"current_acc\",\n",
    "\"Депозиты (вклады)\": \"deposits\",\n",
    "\"Кредиты\": \"credits\",\n",
    "\"Кредитные карты\": \"credit_cards\",\n",
    "\"Дебетовые карты\": \"debit_cards\",\n",
    "\"Денежные переводы и платежи (внутренние и международные)\": \"payments\",\n",
    "\"Инвестиционные продукты (брокерские услуги, ПИФы, доверительное управление)\": \"investments\",\n",
    "\"Банковские гарантии и аккредитивы\": \"garant\",\n",
    "\"Услуги инкассации и хранения ценностей\": \"colect_serv\",\n",
    "\"Зарплатные проекты для организаций\": \"salary\",\n",
    "\"Приложение банка\": \"bank_app\",\n",
    "\"Автокредиты\": \"car_loans\",\n",
    "\"Кэшбэк\": \"cashback\",}\n",
    "len(vocab_dialogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем эмбеддинги по категориям\n",
    "cat_names = []\n",
    "cat_embeddings = []\n",
    "pos_embeddings = []\n",
    "neg_embeddings = []\n",
    "for type_dialogs in vocab_dialogs:\n",
    "    print(type_dialogs)\n",
    "    cat_names.append(ru_en_cat_names[type_dialogs])\n",
    "    pos = list(vocab_dialogs[type_dialogs][0].values())[0]\n",
    "    neg = list(vocab_dialogs[type_dialogs][1].values())[0]\n",
    "    # Формируем эмбеддиги\n",
    "    pos_emb = bertmodel.encode(pos)\n",
    "    neg_emb = bertmodel.encode(neg)\n",
    "    posneg_emb = bertmodel.encode(pos+neg)\n",
    "    posneg_mean_emb = np.array([pos_emb, neg_emb]).mean(axis=0)\n",
    "    \n",
    "    cat_embeddings.append(pos_emb)\n",
    "    cat_embeddings.append(neg_emb)\n",
    "    cat_embeddings.append(posneg_emb)\n",
    "    cat_embeddings.append(posneg_mean_emb)\n",
    "    pos_embeddings.append(pos_emb)\n",
    "    neg_embeddings.append(neg_emb)\n",
    "\n",
    "pos_embeddings = np.array(pos_embeddings)\n",
    "neg_embeddings = np.array(neg_embeddings)\n",
    "\n",
    "cat_embeddings.append(pos_embeddings.mean(axis=0))\n",
    "cat_embeddings.append(neg_embeddings.mean(axis=0))\n",
    "cat_embeddings = np.array(cat_embeddings)\n",
    "\n",
    "cat_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем словарь названий фичей\n",
    "columns_cat_names = []\n",
    "for cat_name in cat_names:\n",
    "    columns_cat_names.append(f'pos_{cat_name}_emb')\n",
    "    columns_cat_names.append(f'neg_{cat_name}_emb')\n",
    "    columns_cat_names.append(f'posneg_{cat_name}_emb')\n",
    "    columns_cat_names.append(f'posneg_mean_{cat_name}_emb')        \n",
    "columns_cat_names += ['positive_emb', 'negative_emb']\n",
    "len(columns_cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Производим расчет косинусного расстояния\n",
    "result_cos_sim = cosine_similarity(embeds, cat_embeddings)\n",
    "result_cos_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем косинунсое расстояние в фичах для каждого диалога\n",
    "all_dialogs_df[columns_cat_names] = result_cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dialogs_df = all_dialogs_df[['client_id', 'event_time', 'embedding']]\n",
    "all_dialogs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert Falsem, \"Ксоинсусное сходство для хороших и плохих проудктов\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# загружаем сэмплерированные данные, для которых будем рассчитывать фичи\n",
    "smpl_Client_Month_df = pq.read_table(PATH_DATASET_OUTPUT + 'result_sample_Client_Month_df_12_06_2024.parquet').to_pandas()\n",
    "smpl_Client_Month_df = smpl_Client_Month_df.set_index(['client_id', 'report_next_end'])\n",
    "smpl_Client_Month_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем временные колонки в сэпмплирвоанные данные, чтобы легче искать по индексу и отдельно по клиенту и по месяцу\n",
    "smpl_Client_Month_df = smpl_Client_Month_df.reset_index()\n",
    "smpl_Client_Month_df['col_client_id'] = smpl_Client_Month_df['client_id']\n",
    "smpl_Client_Month_df['col_report_next_end'] = smpl_Client_Month_df['report_next_end']\n",
    "smpl_Client_Month_df = smpl_Client_Month_df.set_index(['client_id', 'report_next_end'])\n",
    "smpl_Client_Month_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем доп фичи по косинусному сходству"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def calc_embedding_stats(data):\n",
    "    data = select_mon_dlg_df\n",
    "\n",
    "    # Группируем данные по client_id\n",
    "    stats_dialogs = data.groupby('client_id').agg(\n",
    "            sum_pos_current_acc_emb = ('pos_current_acc_emb', sum),\n",
    "            sum_neg_current_acc_emb = ('neg_current_acc_emb', sum),\n",
    "            sum_posneg_current_acc_emb = ('posneg_current_acc_emb', sum),\n",
    "            sum_posneg_mean_current_acc_emb = ('posneg_mean_current_acc_emb', sum),\n",
    "            sum_pos_deposits_emb = ('pos_deposits_emb', sum),\n",
    "            sum_neg_deposits_emb = ('neg_deposits_emb', sum),\n",
    "            sum_posneg_deposits_emb = ('posneg_deposits_emb', sum),\n",
    "            sum_posneg_mean_deposits_emb = ('posneg_mean_deposits_emb', sum),\n",
    "            sum_pos_credits_emb = ('pos_credits_emb', sum),\n",
    "            sum_neg_credits_emb = ('neg_credits_emb', sum),\n",
    "            sum_posneg_credits_emb = ('posneg_credits_emb', sum),\n",
    "            sum_posneg_mean_credits_emb = ('posneg_mean_credits_emb', sum),\n",
    "            sum_pos_credit_cards_emb = ('pos_credit_cards_emb', sum),\n",
    "            sum_neg_credit_cards_emb = ('neg_credit_cards_emb', sum),\n",
    "            sum_posneg_credit_cards_emb = ('posneg_credit_cards_emb', sum),\n",
    "            sum_posneg_mean_credit_cards_emb = ('posneg_mean_credit_cards_emb', sum),\n",
    "            sum_pos_debit_cards_emb = ('pos_debit_cards_emb', sum),\n",
    "            sum_neg_debit_cards_emb = ('neg_debit_cards_emb', sum),\n",
    "            sum_posneg_debit_cards_emb = ('posneg_debit_cards_emb', sum),\n",
    "            sum_posneg_mean_debit_cards_emb = ('posneg_mean_debit_cards_emb', sum),\n",
    "            sum_pos_payments_emb = ('pos_payments_emb', sum),\n",
    "            sum_neg_payments_emb = ('neg_payments_emb', sum),\n",
    "            sum_posneg_payments_emb = ('posneg_payments_emb', sum),\n",
    "            sum_posneg_mean_payments_emb = ('posneg_mean_payments_emb', sum),\n",
    "            sum_pos_investments_emb = ('pos_investments_emb', sum),\n",
    "            sum_neg_investments_emb = ('neg_investments_emb', sum),\n",
    "            sum_posneg_investments_emb = ('posneg_investments_emb', sum),\n",
    "            sum_posneg_mean_investments_emb = ('posneg_mean_investments_emb', sum),\n",
    "            sum_pos_garant_emb = ('pos_garant_emb', sum),\n",
    "            sum_neg_garant_emb = ('neg_garant_emb', sum),\n",
    "            sum_posneg_garant_emb = ('posneg_garant_emb', sum),\n",
    "            sum_posneg_mean_garant_emb = ('posneg_mean_garant_emb', sum),\n",
    "            sum_pos_colect_serv_emb = ('pos_colect_serv_emb', sum),\n",
    "            sum_neg_colect_serv_emb = ('neg_colect_serv_emb', sum),\n",
    "            sum_posneg_colect_serv_emb = ('posneg_colect_serv_emb', sum),\n",
    "            sum_posneg_mean_colect_serv_emb = ('posneg_mean_colect_serv_emb', sum),\n",
    "            sum_pos_salary_emb = ('pos_salary_emb', sum),\n",
    "            sum_neg_salary_emb = ('neg_salary_emb', sum),\n",
    "            sum_posneg_salary_emb = ('posneg_salary_emb', sum),\n",
    "            sum_posneg_mean_salary_emb = ('posneg_mean_salary_emb', sum),\n",
    "            sum_pos_bank_app_emb = ('pos_bank_app_emb', sum),\n",
    "            sum_neg_bank_app_emb = ('neg_bank_app_emb', sum),\n",
    "            sum_posneg_bank_app_emb = ('posneg_bank_app_emb', sum),\n",
    "            sum_posneg_mean_bank_app_emb = ('posneg_mean_bank_app_emb', sum),\n",
    "            sum_pos_car_loans_emb = ('pos_car_loans_emb', sum),\n",
    "            sum_neg_car_loans_emb = ('neg_car_loans_emb', sum),\n",
    "            sum_posneg_car_loans_emb = ('posneg_car_loans_emb', sum),\n",
    "            sum_posneg_mean_car_loans_emb = ('posneg_mean_car_loans_emb', sum),\n",
    "            sum_pos_cashback_emb = ('pos_cashback_emb', sum),\n",
    "            sum_neg_cashback_emb = ('neg_cashback_emb', sum),\n",
    "            sum_posneg_cashback_emb = ('posneg_cashback_emb', sum),\n",
    "            sum_posneg_mean_cashback_emb = ('posneg_mean_cashback_emb', sum),\n",
    "            sum_positive_emb = ('positive_emb', sum),\n",
    "            sum_negative_emb = ('negative_emb', sum),\n",
    "    \n",
    "    \n",
    "            mean_pos_current_acc_emb = ('pos_current_acc_emb', np.mean),\n",
    "            mean_neg_current_acc_emb = ('neg_current_acc_emb', np.mean),\n",
    "            mean_posneg_current_acc_emb = ('posneg_current_acc_emb', np.mean),\n",
    "            mean_posneg_mean_current_acc_emb = ('posneg_mean_current_acc_emb', np.mean),\n",
    "            mean_pos_deposits_emb = ('pos_deposits_emb', np.mean),\n",
    "            mean_neg_deposits_emb = ('neg_deposits_emb', np.mean),\n",
    "            mean_posneg_deposits_emb = ('posneg_deposits_emb', np.mean),\n",
    "            mean_posneg_mean_deposits_emb = ('posneg_mean_deposits_emb', np.mean),\n",
    "            mean_pos_credits_emb = ('pos_credits_emb', np.mean),\n",
    "            mean_neg_credits_emb = ('neg_credits_emb', np.mean),\n",
    "            mean_posneg_credits_emb = ('posneg_credits_emb', np.mean),\n",
    "            mean_posneg_mean_credits_emb = ('posneg_mean_credits_emb', np.mean),\n",
    "            mean_pos_credit_cards_emb = ('pos_credit_cards_emb', np.mean),\n",
    "            mean_neg_credit_cards_emb = ('neg_credit_cards_emb', np.mean),\n",
    "            mean_posneg_credit_cards_emb = ('posneg_credit_cards_emb', np.mean),\n",
    "            mean_posneg_mean_credit_cards_emb = ('posneg_mean_credit_cards_emb', np.mean),\n",
    "            mean_pos_debit_cards_emb = ('pos_debit_cards_emb', np.mean),\n",
    "            mean_neg_debit_cards_emb = ('neg_debit_cards_emb', np.mean),\n",
    "            mean_posneg_debit_cards_emb = ('posneg_debit_cards_emb', np.mean),\n",
    "            mean_posneg_mean_debit_cards_emb = ('posneg_mean_debit_cards_emb', np.mean),\n",
    "            mean_pos_payments_emb = ('pos_payments_emb', np.mean),\n",
    "            mean_neg_payments_emb = ('neg_payments_emb', np.mean),\n",
    "            mean_posneg_payments_emb = ('posneg_payments_emb', np.mean),\n",
    "            mean_posneg_mean_payments_emb = ('posneg_mean_payments_emb', np.mean),\n",
    "            mean_pos_investments_emb = ('pos_investments_emb', np.mean),\n",
    "            mean_neg_investments_emb = ('neg_investments_emb', np.mean),\n",
    "            mean_posneg_investments_emb = ('posneg_investments_emb', np.mean),\n",
    "            mean_posneg_mean_investments_emb = ('posneg_mean_investments_emb', np.mean),\n",
    "            mean_pos_garant_emb = ('pos_garant_emb', np.mean),\n",
    "            mean_neg_garant_emb = ('neg_garant_emb', np.mean),\n",
    "            mean_posneg_garant_emb = ('posneg_garant_emb', np.mean),\n",
    "            mean_posneg_mean_garant_emb = ('posneg_mean_garant_emb', np.mean),\n",
    "            mean_pos_colect_serv_emb = ('pos_colect_serv_emb', np.mean),\n",
    "            mean_neg_colect_serv_emb = ('neg_colect_serv_emb', np.mean),\n",
    "            mean_posneg_colect_serv_emb = ('posneg_colect_serv_emb', np.mean),\n",
    "            mean_posneg_mean_colect_serv_emb = ('posneg_mean_colect_serv_emb', np.mean),\n",
    "            mean_pos_salary_emb = ('pos_salary_emb', np.mean),\n",
    "            mean_neg_salary_emb = ('neg_salary_emb', np.mean),\n",
    "            mean_posneg_salary_emb = ('posneg_salary_emb', np.mean),\n",
    "            mean_posneg_mean_salary_emb = ('posneg_mean_salary_emb', np.mean),\n",
    "            mean_pos_bank_app_emb = ('pos_bank_app_emb', np.mean),\n",
    "            mean_neg_bank_app_emb = ('neg_bank_app_emb', np.mean),\n",
    "            mean_posneg_bank_app_emb = ('posneg_bank_app_emb', np.mean),\n",
    "            mean_posneg_mean_bank_app_emb = ('posneg_mean_bank_app_emb', np.mean),\n",
    "            mean_pos_car_loans_emb = ('pos_car_loans_emb', np.mean),\n",
    "            mean_neg_car_loans_emb = ('neg_car_loans_emb', np.mean),\n",
    "            mean_posneg_car_loans_emb = ('posneg_car_loans_emb', np.mean),\n",
    "            mean_posneg_mean_car_loans_emb = ('posneg_mean_car_loans_emb', np.mean),\n",
    "            mean_pos_cashback_emb = ('pos_cashback_emb', np.mean),\n",
    "            mean_neg_cashback_emb = ('neg_cashback_emb', np.mean),\n",
    "            mean_posneg_cashback_emb = ('posneg_cashback_emb', np.mean),\n",
    "            mean_posneg_mean_cashback_emb = ('posneg_mean_cashback_emb', np.mean),\n",
    "            mean_positive_emb = ('positive_emb', np.mean),\n",
    "            mean_negative_emb = ('negative_emb', np.mean),\n",
    "\n",
    "            min_pos_current_acc_emb = ('pos_current_acc_emb', min),\n",
    "            min_neg_current_acc_emb = ('neg_current_acc_emb', min),\n",
    "            min_posneg_current_acc_emb = ('posneg_current_acc_emb', min),\n",
    "            min_posneg_mean_current_acc_emb = ('posneg_mean_current_acc_emb', min),\n",
    "            min_pos_deposits_emb = ('pos_deposits_emb', min),\n",
    "            min_neg_deposits_emb = ('neg_deposits_emb', min),\n",
    "            min_posneg_deposits_emb = ('posneg_deposits_emb', min),\n",
    "            min_posneg_mean_deposits_emb = ('posneg_mean_deposits_emb', min),\n",
    "            min_pos_credits_emb = ('pos_credits_emb', min),\n",
    "            min_neg_credits_emb = ('neg_credits_emb', min),\n",
    "            min_posneg_credits_emb = ('posneg_credits_emb', min),\n",
    "            min_posneg_mean_credits_emb = ('posneg_mean_credits_emb', min),\n",
    "            min_pos_credit_cards_emb = ('pos_credit_cards_emb', min),\n",
    "            min_neg_credit_cards_emb = ('neg_credit_cards_emb', min),\n",
    "            min_posneg_credit_cards_emb = ('posneg_credit_cards_emb', min),\n",
    "            min_posneg_mean_credit_cards_emb = ('posneg_mean_credit_cards_emb', min),\n",
    "            min_pos_debit_cards_emb = ('pos_debit_cards_emb', min),\n",
    "            min_neg_debit_cards_emb = ('neg_debit_cards_emb', min),\n",
    "            min_posneg_debit_cards_emb = ('posneg_debit_cards_emb', min),\n",
    "            min_posneg_mean_debit_cards_emb = ('posneg_mean_debit_cards_emb', min),\n",
    "            min_pos_payments_emb = ('pos_payments_emb', min),\n",
    "            min_neg_payments_emb = ('neg_payments_emb', min),\n",
    "            min_posneg_payments_emb = ('posneg_payments_emb', min),\n",
    "            min_posneg_mean_payments_emb = ('posneg_mean_payments_emb', min),\n",
    "            min_pos_investments_emb = ('pos_investments_emb', min),\n",
    "            min_neg_investments_emb = ('neg_investments_emb', min),\n",
    "            min_posneg_investments_emb = ('posneg_investments_emb', min),\n",
    "            min_posneg_mean_investments_emb = ('posneg_mean_investments_emb', min),\n",
    "            min_pos_garant_emb = ('pos_garant_emb', min),\n",
    "            min_neg_garant_emb = ('neg_garant_emb', min),\n",
    "            min_posneg_garant_emb = ('posneg_garant_emb', min),\n",
    "            min_posneg_mean_garant_emb = ('posneg_mean_garant_emb', min),\n",
    "            min_pos_colect_serv_emb = ('pos_colect_serv_emb', min),\n",
    "            min_neg_colect_serv_emb = ('neg_colect_serv_emb', min),\n",
    "            min_posneg_colect_serv_emb = ('posneg_colect_serv_emb', min),\n",
    "            min_posneg_mean_colect_serv_emb = ('posneg_mean_colect_serv_emb', min),\n",
    "            min_pos_salary_emb = ('pos_salary_emb', min),\n",
    "            min_neg_salary_emb = ('neg_salary_emb', min),\n",
    "            min_posneg_salary_emb = ('posneg_salary_emb', min),\n",
    "            min_posneg_mean_salary_emb = ('posneg_mean_salary_emb', min),\n",
    "            min_pos_bank_app_emb = ('pos_bank_app_emb', min),\n",
    "            min_neg_bank_app_emb = ('neg_bank_app_emb', min),\n",
    "            min_posneg_bank_app_emb = ('posneg_bank_app_emb', min),\n",
    "            min_posneg_mean_bank_app_emb = ('posneg_mean_bank_app_emb', min),\n",
    "            min_pos_car_loans_emb = ('pos_car_loans_emb', min),\n",
    "            min_neg_car_loans_emb = ('neg_car_loans_emb', min),\n",
    "            min_posneg_car_loans_emb = ('posneg_car_loans_emb', min),\n",
    "            min_posneg_mean_car_loans_emb = ('posneg_mean_car_loans_emb', min),\n",
    "            min_pos_cashback_emb = ('pos_cashback_emb', min),\n",
    "            min_neg_cashback_emb = ('neg_cashback_emb', min),\n",
    "            min_posneg_cashback_emb = ('posneg_cashback_emb', min),\n",
    "            min_posneg_mean_cashback_emb = ('posneg_mean_cashback_emb', min),\n",
    "            min_positive_emb = ('positive_emb', min),\n",
    "            min_negative_emb = ('negative_emb', min),\n",
    "    \n",
    "    \n",
    "            max_pos_current_acc_emb = ('pos_current_acc_emb', max),\n",
    "            max_neg_current_acc_emb = ('neg_current_acc_emb', max),\n",
    "            max_posneg_current_acc_emb = ('posneg_current_acc_emb', max),\n",
    "            max_posneg_mean_current_acc_emb = ('posneg_mean_current_acc_emb', max),\n",
    "            max_pos_deposits_emb = ('pos_deposits_emb', max),\n",
    "            max_neg_deposits_emb = ('neg_deposits_emb', max),\n",
    "            max_posneg_deposits_emb = ('posneg_deposits_emb', max),\n",
    "            max_posneg_mean_deposits_emb = ('posneg_mean_deposits_emb', max),\n",
    "            max_pos_credits_emb = ('pos_credits_emb', max),\n",
    "            max_neg_credits_emb = ('neg_credits_emb', max),\n",
    "            max_posneg_credits_emb = ('posneg_credits_emb', max),\n",
    "            max_posneg_mean_credits_emb = ('posneg_mean_credits_emb', max),\n",
    "            max_pos_credit_cards_emb = ('pos_credit_cards_emb', max),\n",
    "            max_neg_credit_cards_emb = ('neg_credit_cards_emb', max),\n",
    "            max_posneg_credit_cards_emb = ('posneg_credit_cards_emb', max),\n",
    "            max_posneg_mean_credit_cards_emb = ('posneg_mean_credit_cards_emb', max),\n",
    "            max_pos_debit_cards_emb = ('pos_debit_cards_emb', max),\n",
    "            max_neg_debit_cards_emb = ('neg_debit_cards_emb', max),\n",
    "            max_posneg_debit_cards_emb = ('posneg_debit_cards_emb', max),\n",
    "            max_posneg_mean_debit_cards_emb = ('posneg_mean_debit_cards_emb', max),\n",
    "            max_pos_payments_emb = ('pos_payments_emb', max),\n",
    "            max_neg_payments_emb = ('neg_payments_emb', max),\n",
    "            max_posneg_payments_emb = ('posneg_payments_emb', max),\n",
    "            max_posneg_mean_payments_emb = ('posneg_mean_payments_emb', max),\n",
    "            max_pos_investments_emb = ('pos_investments_emb', max),\n",
    "            max_neg_investments_emb = ('neg_investments_emb', max),\n",
    "            max_posneg_investments_emb = ('posneg_investments_emb', max),\n",
    "            max_posneg_mean_investments_emb = ('posneg_mean_investments_emb', max),\n",
    "            max_pos_garant_emb = ('pos_garant_emb', max),\n",
    "            max_neg_garant_emb = ('neg_garant_emb', max),\n",
    "            max_posneg_garant_emb = ('posneg_garant_emb', max),\n",
    "            max_posneg_mean_garant_emb = ('posneg_mean_garant_emb', max),\n",
    "            max_pos_colect_serv_emb = ('pos_colect_serv_emb', max),\n",
    "            max_neg_colect_serv_emb = ('neg_colect_serv_emb', max),\n",
    "            max_posneg_colect_serv_emb = ('posneg_colect_serv_emb', max),\n",
    "            max_posneg_mean_colect_serv_emb = ('posneg_mean_colect_serv_emb', max),\n",
    "            max_pos_salary_emb = ('pos_salary_emb', max),\n",
    "            max_neg_salary_emb = ('neg_salary_emb', max),\n",
    "            max_posneg_salary_emb = ('posneg_salary_emb', max),\n",
    "            max_posneg_mean_salary_emb = ('posneg_mean_salary_emb', max),\n",
    "            max_pos_bank_app_emb = ('pos_bank_app_emb', max),\n",
    "            max_neg_bank_app_emb = ('neg_bank_app_emb', max),\n",
    "            max_posneg_bank_app_emb = ('posneg_bank_app_emb', max),\n",
    "            max_posneg_mean_bank_app_emb = ('posneg_mean_bank_app_emb', max),\n",
    "            max_pos_car_loans_emb = ('pos_car_loans_emb', max),\n",
    "            max_neg_car_loans_emb = ('neg_car_loans_emb', max),\n",
    "            max_posneg_car_loans_emb = ('posneg_car_loans_emb', max),\n",
    "            max_posneg_mean_car_loans_emb = ('posneg_mean_car_loans_emb', max),\n",
    "            max_pos_cashback_emb = ('pos_cashback_emb', max),\n",
    "            max_neg_cashback_emb = ('neg_cashback_emb', max),\n",
    "            max_posneg_cashback_emb = ('posneg_cashback_emb', max),\n",
    "            max_posneg_mean_cashback_emb = ('posneg_mean_cashback_emb', max),\n",
    "            max_positive_emb = ('positive_emb', max),\n",
    "            max_negative_emb = ('negative_emb', max),    \n",
    "    \n",
    "            std_pos_current_acc_emb = ('pos_current_acc_emb', np.std),\n",
    "            std_neg_current_acc_emb = ('neg_current_acc_emb', np.std),\n",
    "            std_posneg_current_acc_emb = ('posneg_current_acc_emb', np.std),\n",
    "            std_posneg_mean_current_acc_emb = ('posneg_mean_current_acc_emb', np.std),\n",
    "            std_pos_deposits_emb = ('pos_deposits_emb', np.std),\n",
    "            std_neg_deposits_emb = ('neg_deposits_emb', np.std),\n",
    "            std_posneg_deposits_emb = ('posneg_deposits_emb', np.std),\n",
    "            std_posneg_mean_deposits_emb = ('posneg_mean_deposits_emb', np.std),\n",
    "            std_pos_credits_emb = ('pos_credits_emb', np.std),\n",
    "            std_neg_credits_emb = ('neg_credits_emb', np.std),\n",
    "            std_posneg_credits_emb = ('posneg_credits_emb', np.std),\n",
    "            std_posneg_mean_credits_emb = ('posneg_mean_credits_emb', np.std),\n",
    "            std_pos_credit_cards_emb = ('pos_credit_cards_emb', np.std),\n",
    "            std_neg_credit_cards_emb = ('neg_credit_cards_emb', np.std),\n",
    "            std_posneg_credit_cards_emb = ('posneg_credit_cards_emb', np.std),\n",
    "            std_posneg_mean_credit_cards_emb = ('posneg_mean_credit_cards_emb', np.std),\n",
    "            std_pos_debit_cards_emb = ('pos_debit_cards_emb', np.std),\n",
    "            std_neg_debit_cards_emb = ('neg_debit_cards_emb', np.std),\n",
    "            std_posneg_debit_cards_emb = ('posneg_debit_cards_emb', np.std),\n",
    "            std_posneg_mean_debit_cards_emb = ('posneg_mean_debit_cards_emb', np.std),\n",
    "            std_pos_payments_emb = ('pos_payments_emb', np.std),\n",
    "            std_neg_payments_emb = ('neg_payments_emb', np.std),\n",
    "            std_posneg_payments_emb = ('posneg_payments_emb', np.std),\n",
    "            std_posneg_mean_payments_emb = ('posneg_mean_payments_emb', np.std),\n",
    "            std_pos_investments_emb = ('pos_investments_emb', np.std),\n",
    "            std_neg_investments_emb = ('neg_investments_emb', np.std),\n",
    "            std_posneg_investments_emb = ('posneg_investments_emb', np.std),\n",
    "            std_posneg_mean_investments_emb = ('posneg_mean_investments_emb', np.std),\n",
    "            std_pos_garant_emb = ('pos_garant_emb', np.std),\n",
    "            std_neg_garant_emb = ('neg_garant_emb', np.std),\n",
    "            std_posneg_garant_emb = ('posneg_garant_emb', np.std),\n",
    "            std_posneg_mean_garant_emb = ('posneg_mean_garant_emb', np.std),\n",
    "            std_pos_colect_serv_emb = ('pos_colect_serv_emb', np.std),\n",
    "            std_neg_colect_serv_emb = ('neg_colect_serv_emb', np.std),\n",
    "            std_posneg_colect_serv_emb = ('posneg_colect_serv_emb', np.std),\n",
    "            std_posneg_mean_colect_serv_emb = ('posneg_mean_colect_serv_emb', np.std),\n",
    "            std_pos_salary_emb = ('pos_salary_emb', np.std),\n",
    "            std_neg_salary_emb = ('neg_salary_emb', np.std),\n",
    "            std_posneg_salary_emb = ('posneg_salary_emb', np.std),\n",
    "            std_posneg_mean_salary_emb = ('posneg_mean_salary_emb', np.std),\n",
    "            std_pos_bank_app_emb = ('pos_bank_app_emb', np.std),\n",
    "            std_neg_bank_app_emb = ('neg_bank_app_emb', np.std),\n",
    "            std_posneg_bank_app_emb = ('posneg_bank_app_emb', np.std),\n",
    "            std_posneg_mean_bank_app_emb = ('posneg_mean_bank_app_emb', np.std),\n",
    "            std_pos_car_loans_emb = ('pos_car_loans_emb', np.std),\n",
    "            std_neg_car_loans_emb = ('neg_car_loans_emb', np.std),\n",
    "            std_posneg_car_loans_emb = ('posneg_car_loans_emb', np.std),\n",
    "            std_posneg_mean_car_loans_emb = ('posneg_mean_car_loans_emb', np.std),\n",
    "            std_pos_cashback_emb = ('pos_cashback_emb', np.std),\n",
    "            std_neg_cashback_emb = ('neg_cashback_emb', np.std),\n",
    "            std_posneg_cashback_emb = ('posneg_cashback_emb', np.std),\n",
    "            std_posneg_mean_cashback_emb = ('posneg_mean_cashback_emb', np.std),\n",
    "            std_positive_emb = ('positive_emb', np.std),\n",
    "            std_negative_emb = ('negative_emb', np.std),    \n",
    "            )\n",
    "    return stats_dialogs.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Формируем фичи по таргету\n",
    "start_date = datetime(2022, 1, 1, 0, 0, 0)\n",
    "# end_date = datetime(2023, 1, 1, 0, 0, 0)\n",
    "end_date = all_dialogs_df['event_time'].max()\n",
    "\n",
    "# Итоговый датасет \n",
    "union_cos_dialogs_by_clients_df = pd.DataFrame()\n",
    "\n",
    "# Бежим по месяцам и расчитываем статистики для клиента берем предыдущие месяцы\n",
    "for i in trange(((end_date - start_date).days//30 + 1)):\n",
    "    end_date = start_date + relativedelta(months=1) - relativedelta(days=1)\n",
    "    print(f'start: {start_date}, end: {end_date}')\n",
    "    # Начальная дата за прошедшие полгода\n",
    "    begin_date = end_date - relativedelta(months=6) - relativedelta(days=1)\n",
    "    # Определяем только тех клиентов которые есть в сэмлере для указанной отчетной даты\n",
    "    report_next_end = start_date + relativedelta(months=2) - relativedelta(days=1)\n",
    "    good_slct_clients = smpl_Client_Month_df[smpl_Client_Month_df['col_report_next_end'] == report_next_end]['col_client_id'].unique()\n",
    "\n",
    "    # Берем данные за последний месяц и фильтруем по нужным клиентам \n",
    "    select_mon_dlg_df = all_dialogs_df[all_dialogs_df['event_time'].between(start_date, end_date)]\n",
    "    select_mon_dlg_df = select_mon_dlg_df[select_mon_dlg_df['client_id'].isin(good_slct_clients)]\n",
    "\n",
    "    # Берем данные за последние полгода начиная от даты begin_date и фильтруем по нужным клиентам \n",
    "    select_ftime_dlg_df = all_dialogs_df[all_dialogs_df['event_time'].between(begin_date, end_date)]\n",
    "    select_ftime_dlg_df = select_ftime_dlg_df[select_ftime_dlg_df['client_id'].isin(good_slct_clients)]\n",
    "    \n",
    "    print(select_mon_dlg_df.shape, select_ftime_dlg_df.shape)\n",
    "    \n",
    "    \n",
    "#     select_mon_current_df = all_dialogs_df[all_dialogs_df['event_time'].between(start_date, end_date)]\n",
    "#     select_mon_full_df = all_dialogs_df[all_dialogs_df['event_time'].between(begin_date, end_date)]\n",
    "#     print(select_mon_current_df.shape, select_mon_full_df.shape)\n",
    "    \n",
    "    # client_agg_df = uniq_clients_df.copy()\n",
    "#     client_agg_df = select_mon_full_df[['client_id']].drop_duplicates().copy()\n",
    "#     report_next_end = start_date + relativedelta(months=2) - relativedelta(days=1)\n",
    "#     client_agg_df['report_next_end'] = report_next_end\n",
    "#     client_agg_df = client_agg_df.set_index('client_id')    \n",
    "\n",
    "    pop_mon_stat_dialogs_df = calc_embedding_stats(select_mon_dlg_df).fillna(0)\n",
    "    pop_mon_stat_dialogs_df['report_next_end'] = report_next_end\n",
    "    pop_mon_stat_dialogs_df = pop_mon_stat_dialogs_df.set_index(['client_id', 'report_next_end']).add_prefix('dlg_')\n",
    "    \n",
    "    pop_ftime_stat_dialogs_df = calc_embedding_stats(select_ftime_dlg_df).fillna(0)\n",
    "    pop_ftime_stat_dialogs_df['report_next_end'] = report_next_end\n",
    "    pop_ftime_stat_dialogs_df = pop_ftime_stat_dialogs_df.set_index(['client_id', 'report_next_end']).add_prefix('ftime_dlg_')\n",
    "    \n",
    "    # Объединяем фичи по месяцам и за полгода\n",
    "    pop_ftime_stat_dialogs_df = pop_ftime_stat_dialogs_df.merge(pop_mon_stat_dialogs_df, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # Сводим в единый датафрейм\n",
    "    union_cos_dialogs_by_clients_df = pd.concat([union_cos_dialogs_by_clients_df, pop_ftime_stat_dialogs_df])\n",
    "    \n",
    "    start_date = start_date + relativedelta(months=1)\n",
    "union_cos_dialogs_by_clients_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Сохраняем статистику по косинусной близости\n",
    "union_cos_dialogs_by_clients_df.to_parquet(PATH_DATASET_OUTPUT + 'cos_dialogs_by_clients_df_13_06_2024.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбивка эмбеддинга на подгруппы и рассчет статистик отдельно для них "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "length_embedding = 768\n",
    "part_size = 64 # должно быть одно из делителей 768: 1, 2, 3, 4, 6, 8, 12, 16, 24, 32, 48, 64, 96, 128, 192, 256, 384, 768\n",
    "count_parts_emb = math.ceil(768/part_size)\n",
    "columns_part = []\n",
    "for i in range(count_parts_emb):\n",
    "    columns_part.append(f'{i+1}_part_emb')\n",
    "len(columns_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dialogs_df = all_dialogs_df[['client_id', 'event_time', 'embedding']]\n",
    "all_dialogs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_part_emb_stats(data):\n",
    "    # Группируем данные по client_id\n",
    "    stats_part_emds = data.groupby('client_id').agg(\n",
    "        min__min_1_part_emb = ('min_1_part_emb', min),\n",
    "        min__max_1_part_emb = ('max_1_part_emb', min),\n",
    "        min__sum_1_part_emb = ('sum_1_part_emb', min),\n",
    "        min__std_1_part_emb = ('std_1_part_emb', min),\n",
    "        min__mean_1_part_emb = ('mean_1_part_emb', min),\n",
    "        min__min_2_part_emb = ('min_2_part_emb', min),\n",
    "        min__max_2_part_emb = ('max_2_part_emb', min),\n",
    "        min__sum_2_part_emb = ('sum_2_part_emb', min),\n",
    "        min__std_2_part_emb = ('std_2_part_emb', min),\n",
    "        min__mean_2_part_emb = ('mean_2_part_emb', min),\n",
    "        min__min_3_part_emb = ('min_3_part_emb', min),\n",
    "        min__max_3_part_emb = ('max_3_part_emb', min),\n",
    "        min__sum_3_part_emb = ('sum_3_part_emb', min),\n",
    "        min__std_3_part_emb = ('std_3_part_emb', min),\n",
    "        min__mean_3_part_emb = ('mean_3_part_emb', min),\n",
    "        min__min_4_part_emb = ('min_4_part_emb', min),\n",
    "        min__max_4_part_emb = ('max_4_part_emb', min),\n",
    "        min__sum_4_part_emb = ('sum_4_part_emb', min),\n",
    "        min__std_4_part_emb = ('std_4_part_emb', min),\n",
    "        min__mean_4_part_emb = ('mean_4_part_emb', min),\n",
    "        min__min_5_part_emb = ('min_5_part_emb', min),\n",
    "        min__max_5_part_emb = ('max_5_part_emb', min),\n",
    "        min__sum_5_part_emb = ('sum_5_part_emb', min),\n",
    "        min__std_5_part_emb = ('std_5_part_emb', min),\n",
    "        min__mean_5_part_emb = ('mean_5_part_emb', min),\n",
    "        min__min_6_part_emb = ('min_6_part_emb', min),\n",
    "        min__max_6_part_emb = ('max_6_part_emb', min),\n",
    "        min__sum_6_part_emb = ('sum_6_part_emb', min),\n",
    "        min__std_6_part_emb = ('std_6_part_emb', min),\n",
    "        min__mean_6_part_emb = ('mean_6_part_emb', min),\n",
    "        min__min_7_part_emb = ('min_7_part_emb', min),\n",
    "        min__max_7_part_emb = ('max_7_part_emb', min),\n",
    "        min__sum_7_part_emb = ('sum_7_part_emb', min),\n",
    "        min__std_7_part_emb = ('std_7_part_emb', min),\n",
    "        min__mean_7_part_emb = ('mean_7_part_emb', min),\n",
    "        min__min_8_part_emb = ('min_8_part_emb', min),\n",
    "        min__max_8_part_emb = ('max_8_part_emb', min),\n",
    "        min__sum_8_part_emb = ('sum_8_part_emb', min),\n",
    "        min__std_8_part_emb = ('std_8_part_emb', min),\n",
    "        min__mean_8_part_emb = ('mean_8_part_emb', min),\n",
    "        min__min_9_part_emb = ('min_9_part_emb', min),\n",
    "        min__max_9_part_emb = ('max_9_part_emb', min),\n",
    "        min__sum_9_part_emb = ('sum_9_part_emb', min),\n",
    "        min__std_9_part_emb = ('std_9_part_emb', min),\n",
    "        min__mean_9_part_emb = ('mean_9_part_emb', min),\n",
    "        min__min_10_part_emb = ('min_10_part_emb', min),\n",
    "        min__max_10_part_emb = ('max_10_part_emb', min),\n",
    "        min__sum_10_part_emb = ('sum_10_part_emb', min),\n",
    "        min__std_10_part_emb = ('std_10_part_emb', min),\n",
    "        min__mean_10_part_emb = ('mean_10_part_emb', min),\n",
    "        min__min_11_part_emb = ('min_11_part_emb', min),\n",
    "        min__max_11_part_emb = ('max_11_part_emb', min),\n",
    "        min__sum_11_part_emb = ('sum_11_part_emb', min),\n",
    "        min__std_11_part_emb = ('std_11_part_emb', min),\n",
    "        min__mean_11_part_emb = ('mean_11_part_emb', min),\n",
    "        min__min_12_part_emb = ('min_12_part_emb', min),\n",
    "        min__max_12_part_emb = ('max_12_part_emb', min),\n",
    "        min__sum_12_part_emb = ('sum_12_part_emb', min),\n",
    "        min__std_12_part_emb = ('std_12_part_emb', min),\n",
    "        min__mean_12_part_emb = ('mean_12_part_emb', min),\n",
    "\n",
    "        max__min_1_part_emb = ('min_1_part_emb', max),\n",
    "        max__max_1_part_emb = ('max_1_part_emb', max),\n",
    "        max__sum_1_part_emb = ('sum_1_part_emb', max),\n",
    "        max__std_1_part_emb = ('std_1_part_emb', max),\n",
    "        max__mean_1_part_emb = ('mean_1_part_emb', max),\n",
    "        max__min_2_part_emb = ('min_2_part_emb', max),\n",
    "        max__max_2_part_emb = ('max_2_part_emb', max),\n",
    "        max__sum_2_part_emb = ('sum_2_part_emb', max),\n",
    "        max__std_2_part_emb = ('std_2_part_emb', max),\n",
    "        max__mean_2_part_emb = ('mean_2_part_emb', max),\n",
    "        max__min_3_part_emb = ('min_3_part_emb', max),\n",
    "        max__max_3_part_emb = ('max_3_part_emb', max),\n",
    "        max__sum_3_part_emb = ('sum_3_part_emb', max),\n",
    "        max__std_3_part_emb = ('std_3_part_emb', max),\n",
    "        max__mean_3_part_emb = ('mean_3_part_emb', max),\n",
    "        max__min_4_part_emb = ('min_4_part_emb', max),\n",
    "        max__max_4_part_emb = ('max_4_part_emb', max),\n",
    "        max__sum_4_part_emb = ('sum_4_part_emb', max),\n",
    "        max__std_4_part_emb = ('std_4_part_emb', max),\n",
    "        max__mean_4_part_emb = ('mean_4_part_emb', max),\n",
    "        max__min_5_part_emb = ('min_5_part_emb', max),\n",
    "        max__max_5_part_emb = ('max_5_part_emb', max),\n",
    "        max__sum_5_part_emb = ('sum_5_part_emb', max),\n",
    "        max__std_5_part_emb = ('std_5_part_emb', max),\n",
    "        max__mean_5_part_emb = ('mean_5_part_emb', max),\n",
    "        max__min_6_part_emb = ('min_6_part_emb', max),\n",
    "        max__max_6_part_emb = ('max_6_part_emb', max),\n",
    "        max__sum_6_part_emb = ('sum_6_part_emb', max),\n",
    "        max__std_6_part_emb = ('std_6_part_emb', max),\n",
    "        max__mean_6_part_emb = ('mean_6_part_emb', max),\n",
    "        max__min_7_part_emb = ('min_7_part_emb', max),\n",
    "        max__max_7_part_emb = ('max_7_part_emb', max),\n",
    "        max__sum_7_part_emb = ('sum_7_part_emb', max),\n",
    "        max__std_7_part_emb = ('std_7_part_emb', max),\n",
    "        max__mean_7_part_emb = ('mean_7_part_emb', max),\n",
    "        max__min_8_part_emb = ('min_8_part_emb', max),\n",
    "        max__max_8_part_emb = ('max_8_part_emb', max),\n",
    "        max__sum_8_part_emb = ('sum_8_part_emb', max),\n",
    "        max__std_8_part_emb = ('std_8_part_emb', max),\n",
    "        max__mean_8_part_emb = ('mean_8_part_emb', max),\n",
    "        max__min_9_part_emb = ('min_9_part_emb', max),\n",
    "        max__max_9_part_emb = ('max_9_part_emb', max),\n",
    "        max__sum_9_part_emb = ('sum_9_part_emb', max),\n",
    "        max__std_9_part_emb = ('std_9_part_emb', max),\n",
    "        max__mean_9_part_emb = ('mean_9_part_emb', max),\n",
    "        max__min_10_part_emb = ('min_10_part_emb', max),\n",
    "        max__max_10_part_emb = ('max_10_part_emb', max),\n",
    "        max__sum_10_part_emb = ('sum_10_part_emb', max),\n",
    "        max__std_10_part_emb = ('std_10_part_emb', max),\n",
    "        max__mean_10_part_emb = ('mean_10_part_emb', max),\n",
    "        max__min_11_part_emb = ('min_11_part_emb', max),\n",
    "        max__max_11_part_emb = ('max_11_part_emb', max),\n",
    "        max__sum_11_part_emb = ('sum_11_part_emb', max),\n",
    "        max__std_11_part_emb = ('std_11_part_emb', max),\n",
    "        max__mean_11_part_emb = ('mean_11_part_emb', max),\n",
    "        max__min_12_part_emb = ('min_12_part_emb', max),\n",
    "        max__max_12_part_emb = ('max_12_part_emb', max),\n",
    "        max__sum_12_part_emb = ('sum_12_part_emb', max),\n",
    "        max__std_12_part_emb = ('std_12_part_emb', max),\n",
    "        max__mean_12_part_emb = ('mean_12_part_emb', max),\n",
    "\n",
    "        mean__min_1_part_emb = ('min_1_part_emb', np.mean),\n",
    "        mean__max_1_part_emb = ('max_1_part_emb', np.mean),\n",
    "        mean__sum_1_part_emb = ('sum_1_part_emb', np.mean),\n",
    "        mean__std_1_part_emb = ('std_1_part_emb', np.mean),\n",
    "        mean__mean_1_part_emb = ('mean_1_part_emb', np.mean),\n",
    "        mean__min_2_part_emb = ('min_2_part_emb', np.mean),\n",
    "        mean__max_2_part_emb = ('max_2_part_emb', np.mean),\n",
    "        mean__sum_2_part_emb = ('sum_2_part_emb', np.mean),\n",
    "        mean__std_2_part_emb = ('std_2_part_emb', np.mean),\n",
    "        mean__mean_2_part_emb = ('mean_2_part_emb', np.mean),\n",
    "        mean__min_3_part_emb = ('min_3_part_emb', np.mean),\n",
    "        mean__max_3_part_emb = ('max_3_part_emb', np.mean),\n",
    "        mean__sum_3_part_emb = ('sum_3_part_emb', np.mean),\n",
    "        mean__std_3_part_emb = ('std_3_part_emb', np.mean),\n",
    "        mean__mean_3_part_emb = ('mean_3_part_emb', np.mean),\n",
    "        mean__min_4_part_emb = ('min_4_part_emb', np.mean),\n",
    "        mean__max_4_part_emb = ('max_4_part_emb', np.mean),\n",
    "        mean__sum_4_part_emb = ('sum_4_part_emb', np.mean),\n",
    "        mean__std_4_part_emb = ('std_4_part_emb', np.mean),\n",
    "        mean__mean_4_part_emb = ('mean_4_part_emb', np.mean),\n",
    "        mean__min_5_part_emb = ('min_5_part_emb', np.mean),\n",
    "        mean__max_5_part_emb = ('max_5_part_emb', np.mean),\n",
    "        mean__sum_5_part_emb = ('sum_5_part_emb', np.mean),\n",
    "        mean__std_5_part_emb = ('std_5_part_emb', np.mean),\n",
    "        mean__mean_5_part_emb = ('mean_5_part_emb', np.mean),\n",
    "        mean__min_6_part_emb = ('min_6_part_emb', np.mean),\n",
    "        mean__max_6_part_emb = ('max_6_part_emb', np.mean),\n",
    "        mean__sum_6_part_emb = ('sum_6_part_emb', np.mean),\n",
    "        mean__std_6_part_emb = ('std_6_part_emb', np.mean),\n",
    "        mean__mean_6_part_emb = ('mean_6_part_emb', np.mean),\n",
    "        mean__min_7_part_emb = ('min_7_part_emb', np.mean),\n",
    "        mean__max_7_part_emb = ('max_7_part_emb', np.mean),\n",
    "        mean__sum_7_part_emb = ('sum_7_part_emb', np.mean),\n",
    "        mean__std_7_part_emb = ('std_7_part_emb', np.mean),\n",
    "        mean__mean_7_part_emb = ('mean_7_part_emb', np.mean),\n",
    "        mean__min_8_part_emb = ('min_8_part_emb', np.mean),\n",
    "        mean__max_8_part_emb = ('max_8_part_emb', np.mean),\n",
    "        mean__sum_8_part_emb = ('sum_8_part_emb', np.mean),\n",
    "        mean__std_8_part_emb = ('std_8_part_emb', np.mean),\n",
    "        mean__mean_8_part_emb = ('mean_8_part_emb', np.mean),\n",
    "        mean__min_9_part_emb = ('min_9_part_emb', np.mean),\n",
    "        mean__max_9_part_emb = ('max_9_part_emb', np.mean),\n",
    "        mean__sum_9_part_emb = ('sum_9_part_emb', np.mean),\n",
    "        mean__std_9_part_emb = ('std_9_part_emb', np.mean),\n",
    "        mean__mean_9_part_emb = ('mean_9_part_emb', np.mean),\n",
    "        mean__min_10_part_emb = ('min_10_part_emb', np.mean),\n",
    "        mean__max_10_part_emb = ('max_10_part_emb', np.mean),\n",
    "        mean__sum_10_part_emb = ('sum_10_part_emb', np.mean),\n",
    "        mean__std_10_part_emb = ('std_10_part_emb', np.mean),\n",
    "        mean__mean_10_part_emb = ('mean_10_part_emb', np.mean),\n",
    "        mean__min_11_part_emb = ('min_11_part_emb', np.mean),\n",
    "        mean__max_11_part_emb = ('max_11_part_emb', np.mean),\n",
    "        mean__sum_11_part_emb = ('sum_11_part_emb', np.mean),\n",
    "        mean__std_11_part_emb = ('std_11_part_emb', np.mean),\n",
    "        mean__mean_11_part_emb = ('mean_11_part_emb', np.mean),\n",
    "        mean__min_12_part_emb = ('min_12_part_emb', np.mean),\n",
    "        mean__max_12_part_emb = ('max_12_part_emb', np.mean),\n",
    "        mean__sum_12_part_emb = ('sum_12_part_emb', np.mean),\n",
    "        mean__std_12_part_emb = ('std_12_part_emb', np.mean),\n",
    "        mean__mean_12_part_emb = ('mean_12_part_emb', np.mean),\n",
    "\n",
    "        sum__min_1_part_emb = ('min_1_part_emb', sum),\n",
    "        sum__max_1_part_emb = ('max_1_part_emb', sum),\n",
    "        sum__sum_1_part_emb = ('sum_1_part_emb', sum),\n",
    "        sum__std_1_part_emb = ('std_1_part_emb', sum),\n",
    "        sum__mean_1_part_emb = ('mean_1_part_emb', sum),\n",
    "        sum__min_2_part_emb = ('min_2_part_emb', sum),\n",
    "        sum__max_2_part_emb = ('max_2_part_emb', sum),\n",
    "        sum__sum_2_part_emb = ('sum_2_part_emb', sum),\n",
    "        sum__std_2_part_emb = ('std_2_part_emb', sum),\n",
    "        sum__mean_2_part_emb = ('mean_2_part_emb', sum),\n",
    "        sum__min_3_part_emb = ('min_3_part_emb', sum),\n",
    "        sum__max_3_part_emb = ('max_3_part_emb', sum),\n",
    "        sum__sum_3_part_emb = ('sum_3_part_emb', sum),\n",
    "        sum__std_3_part_emb = ('std_3_part_emb', sum),\n",
    "        sum__mean_3_part_emb = ('mean_3_part_emb', sum),\n",
    "        sum__min_4_part_emb = ('min_4_part_emb', sum),\n",
    "        sum__max_4_part_emb = ('max_4_part_emb', sum),\n",
    "        sum__sum_4_part_emb = ('sum_4_part_emb', sum),\n",
    "        sum__std_4_part_emb = ('std_4_part_emb', sum),\n",
    "        sum__mean_4_part_emb = ('mean_4_part_emb', sum),\n",
    "        sum__min_5_part_emb = ('min_5_part_emb', sum),\n",
    "        sum__max_5_part_emb = ('max_5_part_emb', sum),\n",
    "        sum__sum_5_part_emb = ('sum_5_part_emb', sum),\n",
    "        sum__std_5_part_emb = ('std_5_part_emb', sum),\n",
    "        sum__mean_5_part_emb = ('mean_5_part_emb', sum),\n",
    "        sum__min_6_part_emb = ('min_6_part_emb', sum),\n",
    "        sum__max_6_part_emb = ('max_6_part_emb', sum),\n",
    "        sum__sum_6_part_emb = ('sum_6_part_emb', sum),\n",
    "        sum__std_6_part_emb = ('std_6_part_emb', sum),\n",
    "        sum__mean_6_part_emb = ('mean_6_part_emb', sum),\n",
    "        sum__min_7_part_emb = ('min_7_part_emb', sum),\n",
    "        sum__max_7_part_emb = ('max_7_part_emb', sum),\n",
    "        sum__sum_7_part_emb = ('sum_7_part_emb', sum),\n",
    "        sum__std_7_part_emb = ('std_7_part_emb', sum),\n",
    "        sum__mean_7_part_emb = ('mean_7_part_emb', sum),\n",
    "        sum__min_8_part_emb = ('min_8_part_emb', sum),\n",
    "        sum__max_8_part_emb = ('max_8_part_emb', sum),\n",
    "        sum__sum_8_part_emb = ('sum_8_part_emb', sum),\n",
    "        sum__std_8_part_emb = ('std_8_part_emb', sum),\n",
    "        sum__mean_8_part_emb = ('mean_8_part_emb', sum),\n",
    "        sum__min_9_part_emb = ('min_9_part_emb', sum),\n",
    "        sum__max_9_part_emb = ('max_9_part_emb', sum),\n",
    "        sum__sum_9_part_emb = ('sum_9_part_emb', sum),\n",
    "        sum__std_9_part_emb = ('std_9_part_emb', sum),\n",
    "        sum__mean_9_part_emb = ('mean_9_part_emb', sum),\n",
    "        sum__min_10_part_emb = ('min_10_part_emb', sum),\n",
    "        sum__max_10_part_emb = ('max_10_part_emb', sum),\n",
    "        sum__sum_10_part_emb = ('sum_10_part_emb', sum),\n",
    "        sum__std_10_part_emb = ('std_10_part_emb', sum),\n",
    "        sum__mean_10_part_emb = ('mean_10_part_emb', sum),\n",
    "        sum__min_11_part_emb = ('min_11_part_emb', sum),\n",
    "        sum__max_11_part_emb = ('max_11_part_emb', sum),\n",
    "        sum__sum_11_part_emb = ('sum_11_part_emb', sum),\n",
    "        sum__std_11_part_emb = ('std_11_part_emb', sum),\n",
    "        sum__mean_11_part_emb = ('mean_11_part_emb', sum),\n",
    "        sum__min_12_part_emb = ('min_12_part_emb', sum),\n",
    "        sum__max_12_part_emb = ('max_12_part_emb', sum),\n",
    "        sum__sum_12_part_emb = ('sum_12_part_emb', sum),\n",
    "        sum__std_12_part_emb = ('std_12_part_emb', sum),\n",
    "        sum__mean_12_part_emb = ('mean_12_part_emb', sum),        \n",
    "    )\n",
    "\n",
    "    return stats_part_emds.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Формируем фичи по таргету\n",
    "start_date = datetime(2022, 1, 1, 0, 0, 0)\n",
    "end_date = all_dialogs_df['event_time'].max()\n",
    "\n",
    "# Итоговый датасет \n",
    "union_split_emb_dialogs_by_clients_df = pd.DataFrame()\n",
    "\n",
    "def split_emb(x):\n",
    "    split_embeddings = [x[i*part_size:(i+1)*part_size] for i in range(count_parts_emb)]\n",
    "    return split_embeddings\n",
    "\n",
    "def calc_stat_by_one_emb(data):\n",
    "    for col in columns_part:\n",
    "        data[f'min_{col}'] = data[col].apply(lambda x: np.min(x, axis=0))\n",
    "        data[f'max_{col}'] = data[col].apply(lambda x: np.max(x, axis=0))\n",
    "        data[f'sum_{col}'] = data[col].apply(lambda x: np.sum(x, axis=0))\n",
    "        data[f'std_{col}'] = data[col].apply(lambda x: np.std(x, axis=0))\n",
    "        data[f'mean_{col}'] = data[col].apply(lambda x: np.mean(x, axis=0))    \n",
    "    return data\n",
    "\n",
    "# Бежим по месяцам и расчитываем статистики для клиента берем предыдущие месяцы\n",
    "for i in trange(((end_date - start_date).days//30 + 1)):\n",
    "    end_date = start_date + relativedelta(months=1) - relativedelta(days=1)\n",
    "    print(f'start: {start_date}, end: {end_date}')\n",
    "    # Начальная дата за прошедшие полгода\n",
    "    begin_date = end_date - relativedelta(months=6) - relativedelta(days=1)\n",
    "    # Определяем только тех клиентов которые есть в сэмлере для указанной отчетной даты\n",
    "    report_next_end = start_date + relativedelta(months=2) - relativedelta(days=1)\n",
    "    good_slct_clients = smpl_Client_Month_df[smpl_Client_Month_df['col_report_next_end'] == report_next_end]['col_client_id'].unique()\n",
    "\n",
    "    # Берем данные за последний месяц и фильтруем по нужным клиентам \n",
    "    select_mon_dlg_df = all_dialogs_df[all_dialogs_df['event_time'].between(start_date, end_date)]\n",
    "    select_mon_dlg_df = select_mon_dlg_df[select_mon_dlg_df['client_id'].isin(good_slct_clients)]\n",
    "\n",
    "    # Берем данные за последние полгода начиная от даты begin_date и фильтруем по нужным клиентам \n",
    "    select_ftime_dlg_df = all_dialogs_df[all_dialogs_df['event_time'].between(begin_date, end_date)]\n",
    "    select_ftime_dlg_df = select_ftime_dlg_df[select_ftime_dlg_df['client_id'].isin(good_slct_clients)]\n",
    "\n",
    "    if len(select_ftime_dlg_df) == 0:\n",
    "        start_date = start_date + relativedelta(months=1)\n",
    "        continue\n",
    "\n",
    "    print(select_mon_dlg_df.shape, select_ftime_dlg_df.shape)\n",
    "    # stat_part_emb_dialogs_df = calc_part_emb_stats(select_mon_dlg_df).fillna(0)\n",
    "\n",
    "    select_mon_dlg_df[columns_part] = select_mon_dlg_df['embedding'].apply(lambda x: pd.Series(split_emb(x)))    \n",
    "    select_mon_dlg_df = calc_stat_by_one_emb(select_mon_dlg_df)\n",
    "    \n",
    "    mon_part_emb_stats_df = calc_part_emb_stats(select_mon_dlg_df).fillna(0)\n",
    "    mon_part_emb_stats_df['report_next_end'] = report_next_end\n",
    "    mon_part_emb_stats_df = mon_part_emb_stats_df.set_index(['client_id', 'report_next_end']).add_prefix('dlg_')\n",
    "\n",
    "    \n",
    "    select_ftime_dlg_df[columns_part] = select_ftime_dlg_df['embedding'].apply(lambda x: pd.Series(split_emb(x)))    \n",
    "    select_ftime_dlg_df = calc_stat_by_one_emb(select_ftime_dlg_df)\n",
    "    \n",
    "    ftime_part_emb_stats_df = calc_part_emb_stats(select_ftime_dlg_df).fillna(0)\n",
    "    ftime_part_emb_stats_df['report_next_end'] = report_next_end\n",
    "    ftime_part_emb_stats_df = ftime_part_emb_stats_df.set_index(['client_id', 'report_next_end']).add_prefix('ftime_dlg_')\n",
    "\n",
    "    # Объединяем фичи по месяцам и за полгода\n",
    "    ftime_part_emb_stats_df = ftime_part_emb_stats_df.merge(mon_part_emb_stats_df, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # Сводим в единый датафрейм\n",
    "    union_split_emb_dialogs_by_clients_df = pd.concat([union_split_emb_dialogs_by_clients_df, ftime_part_emb_stats_df])\n",
    "    \n",
    "    start_date = start_date + relativedelta(months=1)\n",
    "union_split_emb_dialogs_by_clients_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(all_dialogs_df['embedding'].values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack(tmp_dialogs_df.apply(np.array).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ftime_part_emb_stats_df.shape\n",
    "# union_split_emb_dialogs_by_clients_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Сохраняем статистику по косинусной близости\n",
    "union_split_emb_dialogs_by_clients_df.to_parquet(PATH_DATASET_OUTPUT + 'part_embed_dialogs_by_clients_df_13_06_2024.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list(select_mon_dlg_df.columns)\n",
    "# mon_part_emb_stats_df\n",
    "union_split_emb_dialogs_by_clients_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = select_ftime_dlg_df.copy()\n",
    "def split_emb(x):\n",
    "    split_embeddings = [x[i*part_size:(i+1)*part_size] for i in range(count_parts_emb)]\n",
    "    return split_embeddings\n",
    "\n",
    "tmp_df[columns_part] = tmp_df['embedding'].apply(lambda x: pd.Series(split_emb(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data['min_1_part_emb'] = data['1_part_emb'].apply(lambda x: np.min(x, axis=0))\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tmp_df\n",
    "for col in columns_part:\n",
    "    print(col)\n",
    "    data[f'min_{col}'] = data[col].apply(lambda x: np.min(x, axis=0))\n",
    "    data[f'max_{col}'] = data[col].apply(lambda x: np.max(x, axis=0))\n",
    "    data[f'sum_{col}'] = data[col].apply(lambda x: np.sum(x, axis=0))\n",
    "    data[f'std_{col}'] = data[col].apply(lambda x: np.std(x, axis=0))\n",
    "    data[f'mean_{col}'] = data[col].apply(lambda x: np.mean(x, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1,2],[2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_dialogs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding_stats(data):\n",
    "    stats = pd.DataFrame()\n",
    "\n",
    "    # Группируем данные по client_id\n",
    "    grouped = data.groupby('client_id')['embedding'].apply(lambda x: np.array(x.tolist()))\n",
    "    # Средний эмбеддинг диалога\n",
    "    stats['mean_embedding'] = grouped.apply(lambda x: np.mean(x, axis=0))\n",
    "    \n",
    "    # Сумма\n",
    "    stats['sum_embedding'] = grouped.apply(lambda x: np.sum(x))\n",
    "    \n",
    "    # Дисперсия эмбеддингов диалога\n",
    "    stats['embedding_variance'] = grouped.apply(lambda x: np.var(x, axis=0).mean())\n",
    "\n",
    "    # Минимальное/максимальное расстояние между эмбеддингами\n",
    "    distances = grouped.apply(lambda x: squareform(pdist(x, 'euclidean')))\n",
    "    stats['min_embedding_distance'] = distances.apply(np.min)\n",
    "    stats['max_embedding_distance'] = distances.apply(np.max)\n",
    "\n",
    "    # Средняя разница между соседними эмбеддингами\n",
    "    stats['mean_consecutive_distance'] = grouped.apply(lambda x: np.mean([np.linalg.norm(x[i] - x[i-1]) for i in range(1, len(x))]))\n",
    "\n",
    "    # Энтропия эмбеддингов диалога\n",
    "    # stats['embedding_entropy'] = grouped.apply(lambda x: np.mean(-np.sum(np.log(np.var(x, axis=0)) * np.var(x, axis=0), axis=1)))\n",
    "    stats['embedding_entropy'] = grouped.apply(lambda x: -np.sum(np.log(np.var(x, axis=0)) * np.var(x, axis=0)))\n",
    "\n",
    "    # Длина диалога в эмбеддингах\n",
    "    stats['embedding_path_length'] = grouped.apply(lambda x: np.sum([np.linalg.norm(x[i] - x[i-1]) for i in range(1, len(x))]))\n",
    "\n",
    "    # Разложение на главные компоненты (PCA) эмбеддингов диалога\n",
    "    stats['pca_embedding'] = grouped.apply(lambda x: PCA().fit_transform(x)[0])\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Формируем фичи по таргету\n",
    "begin_date = datetime(2022, 1, 1, 0, 0, 0)\n",
    "start_date = datetime(2022, 1, 1, 0, 0, 0)\n",
    "\n",
    "end_date = datetime(2023, 1, 31, 0, 0, 0)\n",
    "\n",
    "# Бланк-датафрейм с клиентами \n",
    "uniq_clients_df = all_dialogs_df[['client_id']].drop_duplicates()\n",
    "\n",
    "# Итоговый датасет \n",
    "union_client_agg_df = pd.DataFrame()\n",
    "\n",
    "# Бежим по месяцам и расчитываем статистики для клиента берем предыдущие месяцы\n",
    "for i in trange(((end_date - start_date).days//30 + 1)):\n",
    "    end_date = start_date + relativedelta(months=1) - relativedelta(days=1)\n",
    "    print(f'start: {start_date}, end: {end_date}')    \n",
    "    \n",
    "    select_mon_current_df = all_dialogs_df[all_dialogs_df['event_time'].between(start_date, end_date)]\n",
    "    select_mon_full_df = all_dialogs_df[all_dialogs_df['event_time'].between(begin_date, end_date)]\n",
    "    print(select_mon_current_df.shape, select_mon_full_df.shape)\n",
    "    \n",
    "    # client_agg_df = uniq_clients_df.copy()\n",
    "    client_agg_df = select_mon_full_df[['client_id']].drop_duplicates().copy()\n",
    "    report_next_end = start_date + relativedelta(months=2) - relativedelta(days=1)\n",
    "    client_agg_df['report_next_end'] = report_next_end\n",
    "    client_agg_df = client_agg_df.set_index('client_id')    \n",
    "    \n",
    "    # Считаем статистики только за прошедший месяц\n",
    "    stats_mon = calculate_embedding_stats(select_mon_current_df)\n",
    "    # Считаем статистики за весь прошедший период\n",
    "    stats_fulltime = calculate_embedding_stats(select_mon_full_df)\n",
    "    \n",
    "    client_agg_df = client_agg_df.merge(stats_mon, left_index=True, right_index=True, how='left')\n",
    "    client_agg_df = client_agg_df.merge(stats_fulltime.add_prefix('fullt_'), left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    union_client_agg_df = pd.concat([union_client_agg_df, client_agg_df])\n",
    "\n",
    "    start_date = start_date + relativedelta(months=1)\n",
    "union_client_agg_df.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Уменьшение размера датафрейма, для таргетов, транзакцй и для фичей\n",
    "def series_to_int(col_df:pd.Series):\n",
    "    \"\"\"\n",
    "    Перевод в целочисленные типы\n",
    "    \"\"\"\n",
    "    min_val = col_df.min()\n",
    "    max_val = col_df.max()\n",
    "    if min_val >= -128 and max_val <= 127:\n",
    "        col_df = col_df.astype('int8')\n",
    "    elif min_val >= -32768 and max_val <= 32767:\n",
    "        col_df = col_df.astype('int16')\n",
    "    elif min_val >= -2147483648 and max_val <= 2147483647:\n",
    "        col_df = col_df.astype('int32')\n",
    "    else:\n",
    "        col_df = col_df.astype('int64')\n",
    "    return col_df\n",
    "\n",
    "def compression_df(df:pd.DataFrame(), datetime_cols:List[str]=[], category_cols:List[str]=[]):\n",
    "    \"\"\"\n",
    "    Уменьшение размера датафрейма, для таргетов, транзакцй и для фичей\n",
    "    \"\"\"\n",
    "    float64_cols = list(df.select_dtypes(include='float64'))  \n",
    "    df[float64_cols] = df[float64_cols].astype('float32')\n",
    "    for col in df.columns:\n",
    "        if col in category_cols:\n",
    "            df[col] = df[col].astype('category')\n",
    "        elif col in datetime_cols:\n",
    "            if df[col].dtypes == 'object':\n",
    "                df[col] = pd.to_datetime(df[col])\n",
    "        # Если колонка содержит числа \n",
    "        elif is_integer_dtype(df[col]):\n",
    "            if df[col].dtypes == 'int8':\n",
    "                continue\n",
    "            else:\n",
    "                df[col] = series_to_int(df[col])\n",
    "        elif is_float_dtype(df[col]):\n",
    "            # Возможно ли перевести в число\n",
    "            if np.array_equal(df[col].fillna(0), df[col].fillna(0).astype(int)):\n",
    "                df[col] = df[col].fillna(0)\n",
    "                df[col] = series_to_int(df[col])\n",
    "    return df\n",
    "union_client_agg_df = compression_df(union_client_agg_df, \n",
    "                            datetime_cols=['report_end' ,'report_next_end'],\n",
    "                           )\n",
    "union_client_agg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Сохраняем в файл оптимизированный файл \n",
    "union_client_agg_df.to_parquet(PATH_DATASET_OUTPUT + 'client_agg_dialog_09_06_2024.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Сохраняем в файл оптимизированный файл \n",
    "# # union_client_agg_df.to_parquet(PATH_DATASET_OUTPUT + 'client_agg_dialog_09_06_2024.parquet', engine='pyarrow')\n",
    "# filename = 'sample_client_agg_dialog_09_06_2024'\n",
    "# compression_options = dict(method='zip', archive_name=f'{filename}.csv')\n",
    "# union_client_agg_df.to_csv(f'{filename}.zip', compression=compression_options)\n",
    "# # union_client_agg_df.to_csv(PATH_DATASET_OUTPUT + 'client_agg_dialog_09_06_2024.csv')\n",
    "# union_client_agg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union_client_agg_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union_client_agg_df['report_next_end'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ('2023-01-31 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats#['mean_embedding'] = grouped.apply(lambda x: np.mean(x, axis=0))\n",
    "# grouped.apply(lambda x: np.mean(x, axis=0))\n",
    "# grouped.apply(lambda x: np.sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats_fulltime['mean_embedding'] = stats_fulltime['mean_embedding'].fillna([[0.0]])\n",
    "# stats_fulltime['pca_embedding'] = stats_fulltime['pca_embedding'].fillna([[0.0]])\n",
    "# ser.apply(lambda x: [np.nan] if pd.isnull(x) else x)\n",
    "# stats_fulltime = stats_fulltime.fillna(0)\n",
    "# stats_mon.fillna(0)['pca_embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_agg_df = uniq_clients_df.copy()\n",
    "report_next_end = start_date + relativedelta(months=2) - relativedelta(days=1)\n",
    "client_agg_df['report_next_end'] = report_next_end\n",
    "client_agg_df = client_agg_df.set_index('client_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_agg_df = client_agg_df.merge(stats_mon, left_index=True, right_index=True, how='left')\n",
    "client_agg_df = client_agg_df.merge(stats_fulltime.add_prefix('fullt_'), left_index=True, right_index=True, how='left')\n",
    "client_agg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats_mon.shape\n",
    "# stats_fulltime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_mon_current_df.groupby(by='client_id')['embedding'].agg({\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_mon_current_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "\n",
    "stats_df = calculate_embedding_stats(select_mon_current_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = select_mon_current_df.copy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grouped).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Темпоральные признаки\n",
    "stats['mean_time_between_events'] = grouped.apply(lambda x: np.mean([data.loc[data['client_id'] == client_id, 'event_time'].diff().dt.total_seconds()[i] for i in range(1, len(x))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Все равно в строчке:\n",
    "stats['mean_time_between_events'] = grouped.apply(lambda x, client_id: np.mean([data.loc[data['client_id'] == client_id, 'event_time'].diff().dt.total_seconds()[i] for i in range(1, len(x))]), client_id=data['client_id'])\n",
    "\n",
    "Возникает ошибка:\n",
    "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Темпоральные признаки\n",
    "def get_mean_time_between_events(group):\n",
    "    return np.mean(data[data['client_id'] == group.name]['event_time'].diff().dt.total_seconds()[1:])\n",
    "\n",
    "stats['mean_time_between_events'] = data.groupby('client_id').progress_apply(get_mean_time_between_events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dialogs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Загружаем диалоги клиентов\n",
    "dialog_df = pq.read_table(PATH_DATASET_OUTPUT + 'compress_targets_08_06_2024.parquet').to_pandas()\n",
    "# targets_df = targets_df.rename(columns={'mon': 'report_next_end'})\n",
    "targets_df = targets_df.reset_index()\n",
    "targets_df = targets_df[['client_id', 'mon', 'target_1', 'target_2', 'target_3', 'target_4']]\n",
    "targets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Загружаем факты продаж продуктов по трейн клиентам\n",
    "targets_df = pq.read_table(PATH_DATASET_OUTPUT + 'compress_targets_08_06_2024.parquet').to_pandas()\n",
    "# targets_df = targets_df.rename(columns={'mon': 'report_next_end'})\n",
    "targets_df = targets_df.reset_index()\n",
    "targets_df = targets_df[['client_id', 'mon', 'target_1', 'target_2', 'target_3', 'target_4']]\n",
    "targets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В данных встречаются дубли клиент+отчетный месяц. Там всегда нули, поэтому просто удаляем дубли \n",
    "targets_df = targets_df.drop_duplicates(subset=['client_id', 'mon'])\n",
    "targets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Рассчитываем факт приобретения клиентом когда-либо продукта 1 или 2/3/4\n",
    "def get_group_targets(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    # Факт приобретения клиентом когда-либо продукта 1 или 2/3/4\n",
    "    df['is_target'] = df[['target_1', 'target_2', 'target_3', 'target_4']].max(axis=1)\n",
    "    \n",
    "    # Расширеный факт приобретения клиентом когда-либо группы продуктов \n",
    "    df['is_target_1_2'] = df[['target_1', 'target_2']].max(axis=1)\n",
    "    df['is_target_1_3'] = df[['target_1', 'target_3']].max(axis=1)\n",
    "    df['is_target_1_4'] = df[['target_1', 'target_4']].max(axis=1)\n",
    "    df['is_target_2_3'] = df[['target_2', 'target_3']].max(axis=1)\n",
    "    df['is_target_2_4'] = df[['target_2', 'target_4']].max(axis=1)\n",
    "    df['is_target_3_4'] = df[['target_3', 'target_4']].max(axis=1)\n",
    "\n",
    "    df['is_target_123'] = df[['target_1', 'target_2', 'target_3']].max(axis=1)\n",
    "    df['is_target_134'] = df[['target_1', 'target_3', 'target_4']].max(axis=1)\n",
    "    df['is_target_124'] = df[['target_1', 'target_2', 'target_4']].max(axis=1)\n",
    "    df['is_target_234'] = df[['target_2', 'target_3', 'target_4']].max(axis=1)\n",
    "    \n",
    "    # Второй расширеный факт приобретения клиентом когда-либо группы продуктов \n",
    "    df['is_target_1_and_2'] = np.where(df[['target_1', 'target_2']].sum(axis=1) == 2, 1,0)\n",
    "    df['is_target_1_and_3'] = np.where(df[['target_1', 'target_3']].sum(axis=1) == 2, 1,0)\n",
    "    df['is_target_1_and_4'] = np.where(df[['target_1', 'target_4']].sum(axis=1) == 2, 1,0)\n",
    "    df['is_target_2_and_3'] = np.where(df[['target_2', 'target_3']].sum(axis=1) == 2, 1,0)\n",
    "    df['is_target_2_and_4'] = np.where(df[['target_2', 'target_4']].sum(axis=1) == 2, 1,0)\n",
    "    df['is_target_3_and_4'] = np.where(df[['target_3', 'target_4']].sum(axis=1) == 2, 1,0)\n",
    "    \n",
    "    df['is_target_and_123'] = np.where(df[['target_1', 'target_2', 'target_3']].sum(axis=1) == 2, 1,0)\n",
    "    df['is_target_and_134'] = np.where(df[['target_1', 'target_3', 'target_4']].sum(axis=1) == 2, 1,0)\n",
    "    df['is_target_and_124'] = np.where(df[['target_1', 'target_2', 'target_4']].sum(axis=1) == 2, 1,0)\n",
    "    df['is_target_and_234'] = np.where(df[['target_2', 'target_3', 'target_4']].sum(axis=1) == 2, 1,0)    \n",
    "    \n",
    "    # кол-во купленных продуктов\n",
    "    df['is_target_cnt'] = df[['target_1', 'target_2', 'target_3', 'target_4']].sum(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "targets_df = get_group_targets(targets_df)\n",
    "targets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['target_1', 'target_2', 'target_3', 'target_4',\n",
    "                  'is_target', 'is_target_1_2', 'is_target_1_3',\n",
    "                  'is_target_1_4', 'is_target_2_3', 'is_target_2_4', 'is_target_3_4',\n",
    "                  'is_target_1_and_2', 'is_target_1_and_3', 'is_target_1_and_4',\n",
    "                  'is_target_2_and_3', 'is_target_2_and_4', 'is_target_3_and_4',\n",
    "                  'is_target_123', 'is_target_134', 'is_target_124', 'is_target_234', \n",
    "                  'is_target_cnt']\n",
    "len(target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mon_targets_df = targets_df.groupby(by='mon').agg(\n",
    "    sum_target_1 = ('target_1', sum), \n",
    "    sum_target_2 = ('target_2', sum), \n",
    "    sum_target_3 = ('target_3', sum), \n",
    "    sum_target_4 = ('target_4', sum), \n",
    "    sum_is_target = ('is_target', sum), \n",
    "    sum_is_target_1_2 = ('is_target_1_2', sum), \n",
    "    sum_is_target_1_3 = ('is_target_1_3', sum), \n",
    "    sum_is_target_1_4 = ('is_target_1_4', sum), \n",
    "    sum_is_target_2_3 = ('is_target_2_3', sum), \n",
    "    sum_is_target_2_4 = ('is_target_2_4', sum), \n",
    "    sum_is_target_3_4 = ('is_target_3_4', sum), \n",
    "    sum_is_target_1_and_2 = ('is_target_1_and_2', sum), \n",
    "    sum_is_target_1_and_3 = ('is_target_1_and_3', sum), \n",
    "    sum_is_target_1_and_4 = ('is_target_1_and_4', sum), \n",
    "    sum_is_target_2_and_3 = ('is_target_2_and_3', sum), \n",
    "    sum_is_target_2_and_4 = ('is_target_2_and_4', sum), \n",
    "    sum_is_target_3_and_4 = ('is_target_3_and_4', sum), \n",
    "    sum_is_target_123 = ('is_target_123', sum), \n",
    "    sum_is_target_134 = ('is_target_134', sum), \n",
    "    sum_is_target_124 = ('is_target_124', sum), \n",
    "    sum_is_target_234 = ('is_target_234', sum), \n",
    "    sum_is_target_cnt = ('is_target_cnt', sum),  \n",
    ")\n",
    "mon_targets_df = mon_targets_df.reset_index()\n",
    "mon_targets_df['next_mon'] = mon_targets_df['mon'].shift(1)\n",
    "mon_targets_df['pre_mon'] = mon_targets_df['mon'].shift(-1)\n",
    "\n",
    "mon_targets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Формируем фичи по таргету\n",
    "begin_date = datetime(2022, 1, 1, 0, 0, 0)\n",
    "start_date = datetime(2022, 1, 1, 0, 0, 0)\n",
    "\n",
    "end_date = datetime(2023, 3, 31, 0, 0, 0)\n",
    "\n",
    "# Бланк-датафрейм с клиентами \n",
    "uniq_clients_df = targets_df[['client_id']].drop_duplicates()\n",
    "# Итоговый датасет \n",
    "union_client_agg_df = pd.DataFrame()\n",
    "\n",
    "# Бежим по месяцам и расчитываем статистики для клиента берем предыдущие месяцы\n",
    "for i in trange(((end_date - start_date).days//30 + 1)):\n",
    "    end_date = start_date + relativedelta(months=1) - relativedelta(days=1)\n",
    "    print(f'start: {start_date}, end: {end_date}')    \n",
    "    select_mon_current_df = targets_df[targets_df['mon'].between(start_date, end_date)]\n",
    "    select_mon_full_df = targets_df[targets_df['mon'].between(begin_date, end_date)]\n",
    "    print(select_mon_current_df.shape, select_mon_full_df.shape)\n",
    "    \n",
    "    client_agg_df = uniq_clients_df.copy()\n",
    "    report_next_end = start_date + relativedelta(months=2) - relativedelta(days=1)\n",
    "    client_agg_df['report_next_end'] = report_next_end\n",
    "    client_agg_df = client_agg_df.set_index('client_id')\n",
    "    \n",
    "    select_mon_full_df = select_mon_full_df.set_index('client_id')\n",
    "    for cur_tar in ['target_1', 'target_2', 'target_3', 'target_4', 'is_target']:\n",
    "        # Расчитываем даты первой и последней покупки продукта \n",
    "        min_max_date_buy = select_mon_full_df[select_mon_full_df[cur_tar] == 1].groupby(by='client_id').agg(\n",
    "                                    first_day_buy = ('mon', min),\n",
    "                                    last_day_buy = ('mon', max),\n",
    "        )\n",
    "        #break\n",
    "        client_agg_df = client_agg_df.merge(min_max_date_buy, left_index=True, right_index=True, how='left')\n",
    "        client_agg_df[f'days_first_buy_{cur_tar}'] = (client_agg_df['report_next_end'] - client_agg_df['first_day_buy']).dt.days\n",
    "        client_agg_df[f'days_last_buy_{cur_tar}'] = (client_agg_df['report_next_end'] - client_agg_df['last_day_buy']).dt.days\n",
    "        client_agg_df = client_agg_df.drop(columns=['first_day_buy', 'last_day_buy'])\n",
    "        client_agg_df = client_agg_df.fillna(0)\n",
    "    \n",
    "    # Количество покупок продуктов за весь период\n",
    "    client_agg_df = client_agg_df.merge(\n",
    "            select_mon_full_df.groupby(by='client_id').agg(\n",
    "                    sum_target_1_by_all_period = ('target_1', sum),\n",
    "                    sum_target_2_by_all_period = ('target_2', sum),\n",
    "                    sum_target_3_by_all_period = ('target_3', sum),\n",
    "                    sum_target_4_by_all_period = ('target_4', sum),\n",
    "                ), left_index=True, right_index=True, how='left'\n",
    "            )\n",
    "    \n",
    "    # Доля покупок по продуктам\n",
    "    client_agg_df['sum_all_target_by_all_period'] = client_agg_df[['sum_target_1_by_all_period', 'sum_target_2_by_all_period', 'sum_target_3_by_all_period', 'sum_target_4_by_all_period']].sum(axis=1)\n",
    "    client_agg_df['prc_target_1by_all_trgs'] = (client_agg_df['sum_target_1_by_all_period'] / client_agg_df['sum_all_target_by_all_period']).fillna(0)\n",
    "    client_agg_df['prc_target_2by_all_trgs'] = (client_agg_df['sum_target_2_by_all_period'] / client_agg_df['sum_all_target_by_all_period']).fillna(0)\n",
    "    client_agg_df['prc_target_3by_all_trgs'] = (client_agg_df['sum_target_3_by_all_period'] / client_agg_df['sum_all_target_by_all_period']).fillna(0)\n",
    "    client_agg_df['prc_target_4by_all_trgs'] = (client_agg_df['sum_target_4_by_all_period'] / client_agg_df['sum_all_target_by_all_period']).fillna(0)\n",
    "    \n",
    "    # Сколько в среднем в месяц клиент покупает продуктов \n",
    "    cnt_month = (end_date - begin_date).days / 30\n",
    "    client_agg_df['mean_all_target_by_per_mon'] = client_agg_df['sum_all_target_by_all_period'] / cnt_month\n",
    "    client_agg_df['mean_target_1_by_per_mon'] = client_agg_df['sum_target_1_by_all_period'] / cnt_month\n",
    "    client_agg_df['mean_target_2_by_per_mon'] = client_agg_df['sum_target_2_by_all_period'] / cnt_month\n",
    "    client_agg_df['mean_target_3_by_per_mon'] = client_agg_df['sum_target_3_by_all_period'] / cnt_month\n",
    "    client_agg_df['mean_target_4_by_per_mon'] = client_agg_df['sum_target_4_by_all_period'] / cnt_month    \n",
    "    \n",
    "    # Количество покупок продуктов за 30 дней\n",
    "    client_agg_df = client_agg_df.merge(\n",
    "            select_mon_full_df[select_mon_full_df['mon'] >= report_next_end - relativedelta(months=1)].groupby(by='client_id').agg(\n",
    "                    sum_target_1_by_1_mon = ('target_1', sum),\n",
    "                    sum_target_2_by_1_mon = ('target_2', sum),\n",
    "                    sum_target_3_by_1_mon = ('target_3', sum),\n",
    "                    sum_target_4_by_1_mon = ('target_4', sum),\n",
    "                ), left_index=True, right_index=True, how='left'\n",
    "            )\n",
    "    # Количество покупок продуктов за 60 дней\n",
    "    client_agg_df = client_agg_df.merge(\n",
    "            select_mon_full_df[select_mon_full_df['mon'] >= report_next_end - relativedelta(months=2)].groupby(by='client_id').agg(\n",
    "                    sum_target_1_by_2_mon = ('target_1', sum),\n",
    "                    sum_target_2_by_2_mon = ('target_2', sum),\n",
    "                    sum_target_3_by_2_mon = ('target_3', sum),\n",
    "                    sum_target_4_by_2_mon = ('target_4', sum),\n",
    "                ), left_index=True, right_index=True, how='left'\n",
    "            )\n",
    "    \n",
    "    # Количество покупок продуктов за 90 дней\n",
    "    client_agg_df = client_agg_df.merge(\n",
    "            select_mon_full_df[select_mon_full_df['mon'] >= report_next_end - relativedelta(months=3)].groupby(by='client_id').agg(\n",
    "                    sum_target_1_by_3_mon = ('target_1', sum),\n",
    "                    sum_target_2_by_3_mon = ('target_2', sum),\n",
    "                    sum_target_3_by_3_mon = ('target_3', sum),\n",
    "                    sum_target_4_by_3_mon = ('target_4', sum),\n",
    "                ), left_index=True, right_index=True, how='left'\n",
    "            )\n",
    "    # Количество покупок продуктов за 120 дней\n",
    "    client_agg_df = client_agg_df.merge(\n",
    "            select_mon_full_df[select_mon_full_df['mon'] >= report_next_end - relativedelta(months=4)].groupby(by='client_id').agg(\n",
    "                    sum_target_1_by_4_mon = ('target_1', sum),\n",
    "                    sum_target_2_by_4_mon = ('target_2', sum),\n",
    "                    sum_target_3_by_4_mon = ('target_3', sum),\n",
    "                    sum_target_4_by_4_mon = ('target_4', sum),\n",
    "                ), left_index=True, right_index=True, how='left'\n",
    "            )\n",
    "    # Количество покупок продуктов за 150 дней\n",
    "    client_agg_df = client_agg_df.merge(\n",
    "            select_mon_full_df[select_mon_full_df['mon'] >= report_next_end - relativedelta(months=5)].groupby(by='client_id').agg(\n",
    "                    sum_target_1_by_5_mon = ('target_1', sum),\n",
    "                    sum_target_2_by_5_mon = ('target_2', sum),\n",
    "                    sum_target_3_by_5_mon = ('target_3', sum),\n",
    "                    sum_target_4_by_5_mon = ('target_4', sum),\n",
    "                ), left_index=True, right_index=True, how='left'\n",
    "            )\n",
    "    # Количество покупок продуктов за 180 дней\n",
    "    client_agg_df = client_agg_df.merge(\n",
    "            select_mon_full_df[select_mon_full_df['mon'] >= report_next_end - relativedelta(months=6)].groupby(by='client_id').agg(\n",
    "                    sum_target_1_by_6_mon = ('target_1', sum),\n",
    "                    sum_target_2_by_6_mon = ('target_2', sum),\n",
    "                    sum_target_3_by_6_mon = ('target_3', sum),\n",
    "                    sum_target_4_by_6_mon = ('target_4', sum),\n",
    "                ), left_index=True, right_index=True, how='left'\n",
    "            )\n",
    "    \n",
    "    # Период неактивности    \n",
    "    period_noactive_target = select_mon_full_df[select_mon_full_df['target_1'] == 0].sort_values(by=['client_id', 'mon'])\n",
    "    period_noactive_target['shift_mon'] = period_noactive_target.groupby('client_id')['mon'].shift(1)\n",
    "    period_noactive_target['period_noactive_target'] = (period_noactive_target['mon'] - period_noactive_target['shift_mon']).dt.days.fillna(0)\n",
    "    period_noactive_target = period_noactive_target.groupby(by='client_id').agg(\n",
    "           max_period_noactive_target = ('period_noactive_target', max),\n",
    "           min_period_noactive_target = ('period_noactive_target', min),\n",
    "           avg_period_noactive_target = ('period_noactive_target', np.mean),\n",
    "           median_period_noactive_target = ('period_noactive_target', np.median),\n",
    "    )\n",
    "    client_agg_df = client_agg_df.merge(period_noactive_target, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    union_client_agg_df = pd.concat([union_client_agg_df, client_agg_df])\n",
    "    start_date = start_date + relativedelta(months=1)\n",
    "union_client_agg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Уменьшение размера датафрейма, для таргетов, транзакцй и для фичей\n",
    "def series_to_int(col_df:pd.Series):\n",
    "    \"\"\"\n",
    "    Перевод в целочисленные типы\n",
    "    \"\"\"\n",
    "    min_val = col_df.min()\n",
    "    max_val = col_df.max()\n",
    "    if min_val >= -128 and max_val <= 127:\n",
    "        col_df = col_df.astype('int8')\n",
    "    elif min_val >= -32768 and max_val <= 32767:\n",
    "        col_df = col_df.astype('int16')\n",
    "    elif min_val >= -2147483648 and max_val <= 2147483647:\n",
    "        col_df = col_df.astype('int32')\n",
    "    else:\n",
    "        col_df = col_df.astype('int64')\n",
    "    return col_df\n",
    "\n",
    "def compression_df(df:pd.DataFrame(), datetime_cols:List[str]=[], category_cols:List[str]=[]):\n",
    "    \"\"\"\n",
    "    Уменьшение размера датафрейма, для таргетов, транзакцй и для фичей\n",
    "    \"\"\"\n",
    "    float64_cols = list(df.select_dtypes(include='float64'))  \n",
    "    df[float64_cols] = df[float64_cols].astype('float32')\n",
    "    for col in df.columns:\n",
    "        if col in category_cols:\n",
    "            df[col] = df[col].astype('category')\n",
    "        elif col in datetime_cols:\n",
    "            if df[col].dtypes == 'object':\n",
    "                df[col] = pd.to_datetime(df[col])\n",
    "        # Если колонка содержит числа \n",
    "        elif is_integer_dtype(df[col]):\n",
    "            if df[col].dtypes == 'int8':\n",
    "                continue\n",
    "            else:\n",
    "                df[col] = series_to_int(df[col])\n",
    "        elif is_float_dtype(df[col]):\n",
    "            # Возможно ли перевести в число\n",
    "            if np.array_equal(df[col].fillna(0), df[col].fillna(0).astype(int)):\n",
    "                df[col] = df[col].fillna(0)\n",
    "                df[col] = series_to_int(df[col])\n",
    "    return df\n",
    "union_client_agg_df = compression_df(union_client_agg_df, \n",
    "                            datetime_cols=['report_end' ,'report_next_end'],\n",
    "                           )\n",
    "\n",
    "mon_targets_df = compression_df(mon_targets_df, \n",
    "                            datetime_cols=['mon', 'pre_mon', 'next_mon'],\n",
    "                           )\n",
    "union_client_agg_df.shape, mon_targets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединяем с агрегированными данными по месяцам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union_client_agg_df['report_next_end'].min()\n",
    "union_client_agg_df = union_client_agg_df.reset_index('client_id').set_index('report_next_end')\n",
    "union_client_agg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "union_client_agg_df = union_client_agg_df.merge(\n",
    "                mon_targets_df.drop(columns=['mon', 'next_mon']).set_index('pre_mon').add_prefix('agg_premon_'),\n",
    "                left_index=True,\n",
    "                right_index=True,    \n",
    "                how='left')\n",
    "gc.collect()\n",
    "\n",
    "union_client_agg_df = union_client_agg_df.merge(\n",
    "                mon_targets_df.drop(columns=['pre_mon', 'next_mon']).set_index('mon').add_prefix('agg_curmon_'),\n",
    "                left_index=True,\n",
    "                right_index=True,    \n",
    "                how='left')\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "union_client_agg_df = union_client_agg_df.merge(\n",
    "                mon_targets_df.drop(columns=['pre_mon', 'mon']).set_index('next_mon').add_prefix('agg_nxtmon_'),\n",
    "                left_index=True,\n",
    "                right_index=True,    \n",
    "                how='left')\n",
    "\n",
    "gc.collect()\n",
    "union_client_agg_df = union_client_agg_df.fillna(0)\n",
    "# union_client_agg_df = union_client_agg_df.reset_index().rename(columns={'index': 'report_next_end'}).set_index(['client_id','report_next_end'])\n",
    "union_client_agg_df = union_client_agg_df.reset_index().rename(columns={'index': 'report_next_end'})\n",
    "union_client_agg_df = union_client_agg_df.sort_values(by=['client_id','report_next_end']).set_index(['client_id','report_next_end'])\n",
    "\n",
    "union_client_agg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Сохраняем в файл оптимизированный файл \n",
    "union_client_agg_df.to_parquet(PATH_DATASET_OUTPUT + 'client_agg_target_09_06_2024.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
